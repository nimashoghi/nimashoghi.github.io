---
permalink: /
title: "Nima Shoghi"
excerpt: "About me"
author_profile: true
redirect_from:
  - /about/
  - /about.html
---

{% include base_path %}

I'm a PhD student in Machine Learning at Georgia Tech, where I am focusing on Deep Learning for Scientific Applications under the guidance of [Dr. Pan Li](https://sites.google.com/view/panli-purdue) and [Dr. Victor Fung](https://cse.gatech.edu/people/victor-fung). I earned my B.S. and M.S. degrees in Computer Science from Georgia Tech, during which I conducted research at the High Performance Computer Architecture Lab on accelerating ML training and inference.  Prior to starting my PhD, I completed a two-year AI residency at Meta AI's FAIR Chemistry team, where I worked on developing large pre-trained models, trained on a diverse mixture of chemical data across multiple domains, for general-purpose chemical property prediction. My research interests lie in the development and application of deep learning techniques to challenging problems in science and engineering. I am particularly excited about the potential for deep learning to accelerate discovery and understanding in fields like chemistry and climate science.

My CV is available [here](files/cv.pdf).

Recent Updates
======
* **[May 2025]** I will be starting a **Research Scientist Internship** at Bytedance Research.
* **[Apr 2025]** Our paper on [MatterTune: An Integrated, User-Friendly Platform for Fine-Tuning Atomistic Foundation Models to Accelerate Materials Simulation and Discovery](https://nima.sh/publications/2025-MatterTune-An-Integrated-User-Friendly-Platform-for-Fine-Tuning-Atomistic-Foundation-Models-to-Accelerate-Materials-Simulation-and-Discovery) is now available on [arXiv](https://arxiv.org/abs/2504.10655)!
* **[Sep 2024]** I gave an **invited talk** titled [Unlocking the Potential of Pre-training for Accelerated Discovery in Chemistry](https://nima.sh/talks/2024-09-20-ai-for-science-institute-unlocking-the-potential-of-pre-training-for-accelerated-discovery-in-chemistry) at the AI for Science Institute (AISI) Beijing. [[Slides]](https://nima.sh/aisi-presentation)
* **[Aug 2024]** I gave an **invited talk** titled [Unlocking the Potential of Pre-training for Accelerated Discovery in Chemistry](https://nima.sh/talks/2024-08-27-2024-machine-learning-for-materials-and-molecular-discoveries-symposium-unlocking-the-potential-of-pre-training-for-accelerated-discovery-in-chemistry) at the 2024 Machine Learning for Materials and Molecular Discoveries Symposium in Gothenburg, Sweden. [[Slides]](https://nima.sh/ml2md)
* **[Aug 2024]** I started my **PhD in Machine Learning** at Georgia Tech, where I will be focusing on Deep Learning for Scientific Applications under the guidance of [Dr. Pan Li](https://sites.google.com/view/panli-purdue) and [Dr. Victor Fung](https://cse.gatech.edu/people/victor-fung).
* **[Jul 2024]** I gave an **invited talk** titled [From Molecules to Materials: Pre-training Large Generalizable Models for Atomic Property Prediction](https://nima.sh/talks/2024-07-02-king-abdullah-university-of-science-and-technology-kaust-from-molecules-to-materials-pre-training-large-generalizable-models-for-atomic-property-prediction) at King Abdullah University of Science and Technology (KAUST). [[Slides]](https://nima.sh/jmp-kaust)
* **[Jun 2024]** I gave an **invited talk** titled [From Molecules to Materials: Pre-training Large Generalizable Models for Atomic Property Prediction](https://nima.sh/talks/2024-06-28-ses-ai-from-molecules-to-materials-pre-training-large-generalizable-models-for-atomic-property-prediction.md) at SES AI. [[Slides]](https://nima.sh/jmp-sesai)
* **[Jun 2024]** I started a **machine learning internship** at ProcessMiner, where I will be developing novel pre-trained transformer models trained on manufacturing process data to predict process outcomes and detect anomalies.
* **[May 2024]** I wrote a blog post on [From Molecules to Materials: Pre-training Large Generalizable Models for Atomic Property Prediction](https://portal.valencelabs.com/blogs/post/from-molecules-to-materials-pre-training-large-generalizable-models-for-Q4afm0EdqUEmrqN) for Valence Labs.
* **[Apr 2024]** I gave an **invited talk** titled [From Molecules to Materials: Pre-training Large Generalizable Models for Atomic Property Prediction](https://nima.sh/talks/2024-04-10-molecular-ml-reading-group-from-molecules-to-materials-pre-training-large-generalizable-models-for-atomic-property-prediction) at the Molecular ML Reading Group. [[Slides]](https://nima.sh/jmp-molecularml-presentation) [[Video]](https://youtu.be/HCtBvtHO5Gk)
* **[Jan 2024]** Our paper on [large-scale diverse pre-training for chemical property prediction](https://openreview.net/forum?id=PfPnugdxup) has been accepted to **ICLR 2024**! Please visit our [webpage](https://nima.sh/jmp/) for more information, including an interactive visualization of its embeddings!
* **[Dec 2023]** I will be joining the High Performance Computer Architecture Lab at Georgia Tech as a **Temporary Research Staff** starting in December 2023.
* **[Aug 2023]** I gave a talk on [From Molecules to Materials: Pre-training Large Generalizable Models for Atomic Property Prediction](https://nima.sh/talks/2023-08-01-acs-fall-meeting-from-molecules-to-materials-pre-training-large-generalizable-models-for-atomic-property-prediction) at the ACS Fall Meeting. [[Slides]](https://nima.sh/acs-presentation) [[Video]](https://youtu.be/YI3kFfZjP3g)

Education
======
* Ph.D. in Machine Learning (School of Computational Science and Engineering), **Georgia Institute of Technology**, 2024 - Present
  * *Advisors*: [Dr. Pan Li](https://sites.google.com/view/panli-purdue) and [Dr. Victor Fung](https://cse.gatech.edu/people/victor-fung)
  * *Research Focus*: Deep Learning for Scientific Applications (e.g., Chemistry, Climate Science, etc.)
* M.S. with *Highest Honors* in Computer Science (Machine Learning Specialization), **Georgia Institute of Technology**, 2020 - 2021
* B.S. with *High Honors* in Computer Science (Machine Learning and Devices Threads), **Georgia Institute of Technology**, 2015 - 2019
* International Baccalaureate Diploma, **Druid Hills High School**, 2011 - 2015

Work experience
======
* Research Scientist Intern on the AI for Science Team at **[Bytedance Research](https://bytedance.com/en/)**, May 2025 - Aug 2025 (expected)
  * Will collaborate with multidisciplinary teams to develop foundation models for drug discovery, including computational protein design and molecular conformation analysis.

* Machine Learning Intern at **[ProcessMiner](https://www.processminer.com/)**, Jun 2024 - Aug 2024
  * Developed novel pre-trained transformer models trained on ~500,000 time-series data points from manufacturing processes to predict process outcomes and detect anomalies.

* Temporary Research Staff at the **[High Performance Computer Architecture Lab at Georgia Tech](https://sites.gatech.edu/hparch/)**, Dec 2023 - May 2024
  * Working on efficient inference strategies for pre-trained image diffusion models, with a focus on generating diverse, high-quality images.

* AI Resident at **[Meta Fundamental AI Research (FAIR)](https://ai.meta.com/research/)**, Aug 2021 - Aug 2023
  * Worked on the [Open Catalyst Project](https://opencatalystproject.org/index.html) on the FAIR Chemistry team, focusing on the development of large-scale pre-training methods for chemical property prediction.

* Research Assistant at **[High Performance Computer Architecture Lab at Georgia Tech](https://sites.gatech.edu/hparch/)**, May 2019 - May 2021
  * Developed software-level and hardware-level techniques for accelerating deep learning training and inference.

* Graduate Teaching Assistant at **[Georgia Institute of Technology](https://www.gatech.edu/)**, Aug 2020 - May 2021
  * CS 4510: Automata and Complexity, Spring 2021
  * CS 4510: Automata and Complexity, Fall 2020

Publications
======
(* denotes equal contribution)

  <ul>{% for post in site.publications reversed %}
    {% include archive-single-cv.html %}
  {% endfor %}</ul>

Talks
======
  <ul>{% for post in site.talks reversed %}
    {% include archive-single-talk-cv.html %}
  {% endfor %}</ul>
