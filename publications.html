<!DOCTYPE html><!--rtrE89DNrUWMal_sRfms0--><html lang="en" class="scroll-smooth"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="preload" href="/_next/static/media/2a65768255d6b625-s.p.d19752fb.woff2" as="font" crossorigin="" type="font/woff2"/><link rel="preload" href="/_next/static/media/83afe278b6a6bb3c-s.p.3a6ba036.woff2" as="font" crossorigin="" type="font/woff2"/><link rel="stylesheet" href="/_next/static/chunks/edc9b9eff40ea36b.css" data-precedence="next"/><link rel="preload" as="script" fetchPriority="low" href="/_next/static/chunks/28072458dcfc9429.js"/><script src="/_next/static/chunks/ec91bd5d7f870bf8.js" async=""></script><script src="/_next/static/chunks/09a888bf77d92639.js" async=""></script><script src="/_next/static/chunks/ea24ce1a0e306bf7.js" async=""></script><script src="/_next/static/chunks/turbopack-e4507b5749facecf.js" async=""></script><script src="/_next/static/chunks/8a0e79cbb1274723.js" async=""></script><script src="/_next/static/chunks/febf79354ea0b539.js" async=""></script><script src="/_next/static/chunks/a78e08c828fdf356.js" async=""></script><script src="/_next/static/chunks/04ffb94433a93116.js" async=""></script><script src="/_next/static/chunks/f9e056060c220c2e.js" async=""></script><script src="/_next/static/chunks/e9c835b7a74e008c.js" async=""></script><script src="/_next/static/chunks/31a6224758fe9544.js" async=""></script><meta name="next-size-adjust" content=""/><title>Publications | Nima Shoghi</title><meta name="description" content="Research publications by Nima Shoghi in machine learning, chemistry, and materials science."/><meta name="author" content="Nima Shoghi"/><link rel="manifest" href="/manifest.json"/><meta name="keywords" content="Machine Learning,PhD,Georgia Tech,Deep Learning,AI for Science,Chemistry,Materials Science"/><meta name="creator" content="Nima Shoghi"/><meta name="robots" content="index, follow"/><meta property="og:title" content="Nima Shoghi | ML PhD Student"/><meta property="og:description" content="PhD student in Machine Learning at Georgia Tech, focusing on Deep Learning for Scientific Applications."/><meta property="og:url" content="https://nima.sh"/><meta property="og:site_name" content="Nima Shoghi"/><meta property="og:locale" content="en_US"/><meta property="og:type" content="website"/><meta name="twitter:card" content="summary_large_image"/><meta name="twitter:creator" content="@nimawrites"/><meta name="twitter:title" content="Nima Shoghi | ML PhD Student"/><meta name="twitter:description" content="PhD student in Machine Learning at Georgia Tech, focusing on Deep Learning for Scientific Applications."/><link rel="icon" href="/favicon.ico" sizes="any"/><link rel="icon" href="/favicon.svg" type="image/svg+xml" media="(prefers-color-scheme: light)"/><link rel="icon" href="/favicon-dark.svg" type="image/svg+xml" media="(prefers-color-scheme: dark)"/><link rel="icon" href="/favicon-32.png" type="image/png" sizes="32x32"/><link rel="icon" href="/favicon-16.png" type="image/png" sizes="16x16"/><link rel="icon" href="/favicon-512.png" type="image/png" sizes="512x512" media="(prefers-color-scheme: light)"/><link rel="icon" href="/favicon-dark-512.png" type="image/png" sizes="512x512" media="(prefers-color-scheme: dark)"/><link rel="apple-touch-icon" href="/favicon-192.png" sizes="180x180" type="image/png"/><script src="/_next/static/chunks/a6dad97d9634a72d.js" noModule=""></script></head><body class="inter_786c1081-module__J60SBq__variable playfair_display_bd0c5d65-module___OUtNG__variable font-sans antialiased bg-background text-foreground selection:bg-primary/10 selection:text-primary"><div hidden=""><!--$--><!--/$--></div><script>((a,b,c,d,e,f,g,h)=>{let i=document.documentElement,j=["light","dark"];function k(b){var c;(Array.isArray(a)?a:[a]).forEach(a=>{let c="class"===a,d=c&&f?e.map(a=>f[a]||a):e;c?(i.classList.remove(...d),i.classList.add(f&&f[b]?f[b]:b)):i.setAttribute(a,b)}),c=b,h&&j.includes(c)&&(i.style.colorScheme=c)}if(d)k(d);else try{let a=localStorage.getItem(b)||c,d=g&&"system"===a?window.matchMedia("(prefers-color-scheme: dark)").matches?"dark":"light":a;k(d)}catch(a){}})("class","theme","system",null,["light","dark"],null,true,true)</script><div class="relative flex min-h-screen flex-col"><div class="fixed inset-0 -z-10 h-full w-full bg-background overflow-hidden"><div class="absolute inset-0 bg-[linear-gradient(to_right,#8080800a_1px,transparent_1px),linear-gradient(to_bottom,#8080800a_1px,transparent_1px)] bg-size-[24px_24px]"></div><div class="absolute left-0 right-0 top-[-10%] -z-10 m-auto h-125 w-125 rounded-full bg-primary/20 opacity-30 blur-[100px]"></div><div class="absolute bottom-[-10%] right-[-10%] -z-10 h-100 w-100 rounded-full bg-primary/10 opacity-20 blur-[100px]"></div></div><header class="sticky top-0 z-50 w-full border-b border-border/40 bg-background/95 backdrop-blur supports-backdrop-filter:bg-background/60"><nav class="mx-auto flex h-16 max-w-5xl items-center justify-between px-4 sm:px-6 lg:px-8"><a class="text-xl font-semibold tracking-tight text-foreground transition-colors hover:text-primary" href="/">Nima Shoghi</a><div class="hidden md:flex md:items-center md:gap-1"><a class="rounded-md px-3 py-2 text-sm font-medium transition-colors text-muted-foreground hover:bg-accent hover:text-accent-foreground" href="/">Home</a><a class="rounded-md px-3 py-2 text-sm font-medium transition-colors text-muted-foreground hover:bg-accent hover:text-accent-foreground" href="/experience">Experience</a><a class="rounded-md px-3 py-2 text-sm font-medium transition-colors bg-accent text-accent-foreground" href="/publications">Publications</a><a class="rounded-md px-3 py-2 text-sm font-medium transition-colors text-muted-foreground hover:bg-accent hover:text-accent-foreground" href="/talks">Talks</a><a class="rounded-md px-3 py-2 text-sm font-medium transition-colors text-muted-foreground hover:bg-accent hover:text-accent-foreground" target="_blank" rel="noopener noreferrer" href="/cv.pdf">CV</a><button data-slot="button" data-variant="ghost" data-size="icon" class="inline-flex items-center justify-center gap-2 whitespace-nowrap rounded-md text-sm font-medium transition-all disabled:pointer-events-none disabled:opacity-50 [&amp;_svg]:pointer-events-none [&amp;_svg:not([class*=&#x27;size-&#x27;])]:size-4 shrink-0 [&amp;_svg]:shrink-0 outline-none focus-visible:border-ring focus-visible:ring-ring/50 focus-visible:ring-[3px] aria-invalid:ring-destructive/20 dark:aria-invalid:ring-destructive/40 aria-invalid:border-destructive hover:bg-accent hover:text-accent-foreground dark:hover:bg-accent/50 size-9" disabled=""><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-sun h-4 w-4" aria-hidden="true"><circle cx="12" cy="12" r="4"></circle><path d="M12 2v2"></path><path d="M12 20v2"></path><path d="m4.93 4.93 1.41 1.41"></path><path d="m17.66 17.66 1.41 1.41"></path><path d="M2 12h2"></path><path d="M20 12h2"></path><path d="m6.34 17.66-1.41 1.41"></path><path d="m19.07 4.93-1.41 1.41"></path></svg><span class="sr-only">Toggle theme</span></button></div><div class="flex items-center gap-2 md:hidden"><button data-slot="button" data-variant="ghost" data-size="icon" class="inline-flex items-center justify-center gap-2 whitespace-nowrap rounded-md text-sm font-medium transition-all disabled:pointer-events-none disabled:opacity-50 [&amp;_svg]:pointer-events-none [&amp;_svg:not([class*=&#x27;size-&#x27;])]:size-4 shrink-0 [&amp;_svg]:shrink-0 outline-none focus-visible:border-ring focus-visible:ring-ring/50 focus-visible:ring-[3px] aria-invalid:ring-destructive/20 dark:aria-invalid:ring-destructive/40 aria-invalid:border-destructive hover:bg-accent hover:text-accent-foreground dark:hover:bg-accent/50 size-9" disabled=""><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-sun h-4 w-4" aria-hidden="true"><circle cx="12" cy="12" r="4"></circle><path d="M12 2v2"></path><path d="M12 20v2"></path><path d="m4.93 4.93 1.41 1.41"></path><path d="m17.66 17.66 1.41 1.41"></path><path d="M2 12h2"></path><path d="M20 12h2"></path><path d="m6.34 17.66-1.41 1.41"></path><path d="m19.07 4.93-1.41 1.41"></path></svg><span class="sr-only">Toggle theme</span></button><button data-slot="sheet-trigger" data-variant="ghost" data-size="icon" class="inline-flex items-center justify-center gap-2 whitespace-nowrap rounded-md text-sm font-medium transition-all disabled:pointer-events-none disabled:opacity-50 [&amp;_svg]:pointer-events-none [&amp;_svg:not([class*=&#x27;size-&#x27;])]:size-4 shrink-0 [&amp;_svg]:shrink-0 outline-none focus-visible:border-ring focus-visible:ring-ring/50 focus-visible:ring-[3px] aria-invalid:ring-destructive/20 dark:aria-invalid:ring-destructive/40 aria-invalid:border-destructive hover:bg-accent hover:text-accent-foreground dark:hover:bg-accent/50 size-9" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_mlb_" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-menu h-5 w-5" aria-hidden="true"><path d="M4 5h16"></path><path d="M4 12h16"></path><path d="M4 19h16"></path></svg><span class="sr-only">Toggle menu</span></button></div></nav></header><main class="flex-1"><div class="mx-auto max-w-5xl px-4 sm:px-6 lg:px-8" style="opacity:0"><section class="py-12"><div class="mb-8"><h2 class="font-serif text-3xl font-bold tracking-tight text-foreground sm:text-4xl">Publications</h2><p class="mt-2 text-lg text-muted-foreground">(* denotes equal contribution)</p></div><div class="space-y-12"><div style="opacity:0;transform:translateY(20px)"><h3 class="mb-6 text-2xl font-serif font-medium text-foreground/80 pl-2 border-l-2 border-primary/20">2025</h3><div class="grid gap-4"><div><div data-slot="card" class="text-card-foreground flex flex-col gap-6 rounded-xl border py-6 shadow-sm group relative overflow-hidden border-border/50 bg-card/50 transition-all hover:border-primary/20 hover:shadow-lg hover:shadow-primary/5"><div class="absolute inset-0 bg-linear-to-br from-primary/5 via-transparent to-transparent opacity-0 transition-opacity group-hover:opacity-100"></div><div class="flex flex-col md:flex-row"><div class="relative w-full md:w-64 shrink-0 overflow-hidden md:border-r border-border/50 bg-muted/30"><button class="w-full h-full cursor-zoom-in focus:outline-none" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_1lkd5fiutb_" data-state="closed"><div class="aspect-video md:h-full md:aspect-auto relative"><img alt="Figure from MatterTune: An Integrated, User-Friendly Platform for Fine-Tuning Atomistic Foundation Models to Accelerate Materials Simulation and Discovery" loading="lazy" decoding="async" data-nimg="fill" class="object-contain p-2 transition-transform duration-500 group-hover:scale-105" style="position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;color:transparent" src="/images/papers/mattertune/featured.jpg"/></div></button></div><div class="flex-1 min-w-0 flex flex-col"><div data-slot="card-header" class="@container/card-header grid auto-rows-min grid-rows-[auto_auto] items-start gap-2 px-6 has-data-[slot=card-action]:grid-cols-[1fr_auto] [.border-b]:pb-6 pb-3"><div class="flex items-start justify-between gap-4"><div class="flex-1 space-y-2"><h3 class="font-serif text-xl font-medium leading-tight text-foreground group-hover:text-primary transition-colors"><a target="_blank" rel="noopener noreferrer" class="flex items-center gap-2 hover:underline decoration-primary/30 underline-offset-4" href="https://arxiv.org/abs/2504.10655">MatterTune: An Integrated, User-Friendly Platform for Fine-Tuning Atomistic Foundation Models to Accelerate Materials Simulation and Discovery<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-arrow-up-right h-4 w-4 opacity-50" aria-hidden="true"><path d="M7 7h10v10"></path><path d="M7 17 17 7"></path></svg></a></h3><div class="flex flex-wrap items-center gap-2"><span data-slot="badge" class="inline-flex items-center justify-center rounded-full border px-2 py-0.5 text-xs w-fit whitespace-nowrap shrink-0 [&amp;&gt;svg]:size-3 gap-1 [&amp;&gt;svg]:pointer-events-none focus-visible:border-ring focus-visible:ring-ring/50 focus-visible:ring-[3px] aria-invalid:ring-destructive/20 dark:aria-invalid:ring-destructive/40 aria-invalid:border-destructive transition-[color,box-shadow] overflow-hidden border-transparent text-secondary-foreground [a&amp;]:hover:bg-secondary/90 bg-secondary/50 font-normal">arXiv preprint</span><span data-slot="badge" class="inline-flex items-center justify-center rounded-full border px-2 py-0.5 text-xs w-fit whitespace-nowrap shrink-0 [&amp;&gt;svg]:size-3 gap-1 [&amp;&gt;svg]:pointer-events-none focus-visible:border-ring focus-visible:ring-ring/50 focus-visible:ring-[3px] aria-invalid:ring-destructive/20 dark:aria-invalid:ring-destructive/40 aria-invalid:border-destructive transition-[color,box-shadow] overflow-hidden [a&amp;]:hover:bg-accent [a&amp;]:hover:text-accent-foreground font-normal text-muted-foreground">2025</span><span data-slot="badge" class="inline-flex items-center justify-center rounded-full border px-2 py-0.5 text-xs font-medium w-fit whitespace-nowrap shrink-0 [&amp;&gt;svg]:size-3 gap-1 [&amp;&gt;svg]:pointer-events-none focus-visible:border-ring focus-visible:ring-ring/50 focus-visible:ring-[3px] aria-invalid:ring-destructive/20 dark:aria-invalid:ring-destructive/40 aria-invalid:border-destructive transition-[color,box-shadow] overflow-hidden [a&amp;]:hover:bg-primary/90 bg-primary/10 text-primary hover:bg-primary/20 border-primary/20">Featured</span></div></div></div></div><div data-slot="card-content" class="px-6 pt-0 relative z-10 flex-1 flex flex-col justify-between"><div><p class="text-sm text-muted-foreground font-medium">Lingyu Kong, <b>Nima Shoghi</b>, Guoxiang Hu, Pan Li, Victor Fung</p><p class="mt-2 text-sm leading-relaxed text-foreground/80">Introduces MatterTune, a modular platform that enables fine-tuning of pre-trained atomistic foundation models for materials science applications.</p></div><div class="mt-4 flex"><a target="_blank" rel="noopener noreferrer" class="inline-flex items-center gap-1.5 text-xs font-medium text-primary hover:text-primary/80 transition-colors" href="https://arxiv.org/abs/2504.10655"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-file-text h-3.5 w-3.5" aria-hidden="true"><path d="M6 22a2 2 0 0 1-2-2V4a2 2 0 0 1 2-2h8a2.4 2.4 0 0 1 1.704.706l3.588 3.588A2.4 2.4 0 0 1 20 8v12a2 2 0 0 1-2 2z"></path><path d="M14 2v5a1 1 0 0 0 1 1h5"></path><path d="M10 9H8"></path><path d="M16 13H8"></path><path d="M16 17H8"></path></svg>Read Paper</a></div></div></div></div></div></div></div></div><div style="opacity:0;transform:translateY(20px)"><h3 class="mb-6 text-2xl font-serif font-medium text-foreground/80 pl-2 border-l-2 border-primary/20">2024</h3><div class="grid gap-4"><div><div data-slot="card" class="text-card-foreground flex flex-col gap-6 rounded-xl border py-6 shadow-sm group relative overflow-hidden border-border/50 bg-card/50 transition-all hover:border-primary/20 hover:shadow-lg hover:shadow-primary/5"><div class="absolute inset-0 bg-linear-to-br from-primary/5 via-transparent to-transparent opacity-0 transition-opacity group-hover:opacity-100"></div><div class="flex flex-col md:flex-row"><div class="relative w-full md:w-64 shrink-0 overflow-hidden md:border-r border-border/50 bg-muted/30"><button class="w-full h-full cursor-zoom-in focus:outline-none" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_39kl5fiutb_" data-state="closed"><div class="aspect-video md:h-full md:aspect-auto relative"><img alt="Figure from From Molecules to Materials: Pre-training Large Generalizable Models for Atomic Property Prediction" loading="lazy" decoding="async" data-nimg="fill" class="object-contain p-2 transition-transform duration-500 group-hover:scale-105" style="position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;color:transparent" src="/images/papers/jmp/featured.jpg"/></div></button></div><div class="flex-1 min-w-0 flex flex-col"><div data-slot="card-header" class="@container/card-header grid auto-rows-min grid-rows-[auto_auto] items-start gap-2 px-6 has-data-[slot=card-action]:grid-cols-[1fr_auto] [.border-b]:pb-6 pb-3"><div class="flex items-start justify-between gap-4"><div class="flex-1 space-y-2"><h3 class="font-serif text-xl font-medium leading-tight text-foreground group-hover:text-primary transition-colors"><a target="_blank" rel="noopener noreferrer" class="flex items-center gap-2 hover:underline decoration-primary/30 underline-offset-4" href="https://arxiv.org/abs/2310.16802">From Molecules to Materials: Pre-training Large Generalizable Models for Atomic Property Prediction<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-arrow-up-right h-4 w-4 opacity-50" aria-hidden="true"><path d="M7 7h10v10"></path><path d="M7 17 17 7"></path></svg></a></h3><div class="flex flex-wrap items-center gap-2"><span data-slot="badge" class="inline-flex items-center justify-center rounded-full border px-2 py-0.5 text-xs w-fit whitespace-nowrap shrink-0 [&amp;&gt;svg]:size-3 gap-1 [&amp;&gt;svg]:pointer-events-none focus-visible:border-ring focus-visible:ring-ring/50 focus-visible:ring-[3px] aria-invalid:ring-destructive/20 dark:aria-invalid:ring-destructive/40 aria-invalid:border-destructive transition-[color,box-shadow] overflow-hidden border-transparent text-secondary-foreground [a&amp;]:hover:bg-secondary/90 bg-secondary/50 font-normal">International Conference on Learning Representations (ICLR)</span><span data-slot="badge" class="inline-flex items-center justify-center rounded-full border px-2 py-0.5 text-xs w-fit whitespace-nowrap shrink-0 [&amp;&gt;svg]:size-3 gap-1 [&amp;&gt;svg]:pointer-events-none focus-visible:border-ring focus-visible:ring-ring/50 focus-visible:ring-[3px] aria-invalid:ring-destructive/20 dark:aria-invalid:ring-destructive/40 aria-invalid:border-destructive transition-[color,box-shadow] overflow-hidden [a&amp;]:hover:bg-accent [a&amp;]:hover:text-accent-foreground font-normal text-muted-foreground">2024</span><span data-slot="badge" class="inline-flex items-center justify-center rounded-full border px-2 py-0.5 text-xs font-medium w-fit whitespace-nowrap shrink-0 [&amp;&gt;svg]:size-3 gap-1 [&amp;&gt;svg]:pointer-events-none focus-visible:border-ring focus-visible:ring-ring/50 focus-visible:ring-[3px] aria-invalid:ring-destructive/20 dark:aria-invalid:ring-destructive/40 aria-invalid:border-destructive transition-[color,box-shadow] overflow-hidden [a&amp;]:hover:bg-primary/90 bg-primary/10 text-primary hover:bg-primary/20 border-primary/20">Featured</span></div></div></div></div><div data-slot="card-content" class="px-6 pt-0 relative z-10 flex-1 flex flex-col justify-between"><div><p class="text-sm text-muted-foreground font-medium"><b>Nima Shoghi</b>, Adeesh Kolluru, John Kitchin, Zachary Ulissi, C. Lawrence Zitnick, Brandon Wood</p><p class="mt-2 text-sm leading-relaxed text-foreground/80">Introduces Joint Multi-domain Pre-training (JMP), a supervised pre-training strategy that leverages diverse data to advance atomic property prediction across chemical domains, achieving state-of-the-art performance on 34 out of 40 downstream tasks.</p></div><div class="mt-4 flex"><a target="_blank" rel="noopener noreferrer" class="inline-flex items-center gap-1.5 text-xs font-medium text-primary hover:text-primary/80 transition-colors" href="https://arxiv.org/abs/2310.16802"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-file-text h-3.5 w-3.5" aria-hidden="true"><path d="M6 22a2 2 0 0 1-2-2V4a2 2 0 0 1 2-2h8a2.4 2.4 0 0 1 1.704.706l3.588 3.588A2.4 2.4 0 0 1 20 8v12a2 2 0 0 1-2 2z"></path><path d="M14 2v5a1 1 0 0 0 1 1h5"></path><path d="M10 9H8"></path><path d="M16 13H8"></path><path d="M16 17H8"></path></svg>Read Paper</a></div></div></div></div></div></div><div><div data-slot="card" class="text-card-foreground flex flex-col gap-6 rounded-xl border py-6 shadow-sm group relative overflow-hidden border-border/50 bg-card/50 transition-all hover:border-primary/20 hover:shadow-lg hover:shadow-primary/5"><div class="absolute inset-0 bg-linear-to-br from-primary/5 via-transparent to-transparent opacity-0 transition-opacity group-hover:opacity-100"></div><div class="flex flex-col md:flex-row"><div class="relative w-full md:w-64 shrink-0 overflow-hidden md:border-r border-border/50 bg-muted/30"><button class="w-full h-full cursor-zoom-in focus:outline-none" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_3akl5fiutb_" data-state="closed"><div class="aspect-video md:h-full md:aspect-auto relative"><img alt="Figure from Distribution Learning for Molecular Regression" loading="lazy" decoding="async" data-nimg="fill" class="object-contain p-2 transition-transform duration-500 group-hover:scale-105" style="position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;color:transparent" src="/images/papers/distribution-learning-mol-regression/featured.jpg"/></div></button></div><div class="flex-1 min-w-0 flex flex-col"><div data-slot="card-header" class="@container/card-header grid auto-rows-min grid-rows-[auto_auto] items-start gap-2 px-6 has-data-[slot=card-action]:grid-cols-[1fr_auto] [.border-b]:pb-6 pb-3"><div class="flex items-start justify-between gap-4"><div class="flex-1 space-y-2"><h3 class="font-serif text-xl font-medium leading-tight text-foreground group-hover:text-primary transition-colors"><a target="_blank" rel="noopener noreferrer" class="flex items-center gap-2 hover:underline decoration-primary/30 underline-offset-4" href="https://arxiv.org/abs/2407.20475">Distribution Learning for Molecular Regression<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-arrow-up-right h-4 w-4 opacity-50" aria-hidden="true"><path d="M7 7h10v10"></path><path d="M7 17 17 7"></path></svg></a></h3><div class="flex flex-wrap items-center gap-2"><span data-slot="badge" class="inline-flex items-center justify-center rounded-full border px-2 py-0.5 text-xs w-fit whitespace-nowrap shrink-0 [&amp;&gt;svg]:size-3 gap-1 [&amp;&gt;svg]:pointer-events-none focus-visible:border-ring focus-visible:ring-ring/50 focus-visible:ring-[3px] aria-invalid:ring-destructive/20 dark:aria-invalid:ring-destructive/40 aria-invalid:border-destructive transition-[color,box-shadow] overflow-hidden border-transparent text-secondary-foreground [a&amp;]:hover:bg-secondary/90 bg-secondary/50 font-normal">arXiv preprint arXiv:2407.20475</span><span data-slot="badge" class="inline-flex items-center justify-center rounded-full border px-2 py-0.5 text-xs w-fit whitespace-nowrap shrink-0 [&amp;&gt;svg]:size-3 gap-1 [&amp;&gt;svg]:pointer-events-none focus-visible:border-ring focus-visible:ring-ring/50 focus-visible:ring-[3px] aria-invalid:ring-destructive/20 dark:aria-invalid:ring-destructive/40 aria-invalid:border-destructive transition-[color,box-shadow] overflow-hidden [a&amp;]:hover:bg-accent [a&amp;]:hover:text-accent-foreground font-normal text-muted-foreground">2024</span></div></div></div></div><div data-slot="card-content" class="px-6 pt-0 relative z-10 flex-1 flex flex-col justify-between"><div><p class="text-sm text-muted-foreground font-medium"><b>Nima Shoghi</b>, Pooya Shoghi, Anuroop Sriram, Abhishek Das</p><p class="mt-2 text-sm leading-relaxed text-foreground/80">Introduces Distributional Mixture of Experts (DMoE), a robust method for molecular property regression that outperforms baselines on multiple datasets and architectures.</p></div><div class="mt-4 flex"><a target="_blank" rel="noopener noreferrer" class="inline-flex items-center gap-1.5 text-xs font-medium text-primary hover:text-primary/80 transition-colors" href="https://arxiv.org/abs/2407.20475"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-file-text h-3.5 w-3.5" aria-hidden="true"><path d="M6 22a2 2 0 0 1-2-2V4a2 2 0 0 1 2-2h8a2.4 2.4 0 0 1 1.704.706l3.588 3.588A2.4 2.4 0 0 1 20 8v12a2 2 0 0 1-2 2z"></path><path d="M14 2v5a1 1 0 0 0 1 1h5"></path><path d="M10 9H8"></path><path d="M16 13H8"></path><path d="M16 17H8"></path></svg>Read Paper</a></div></div></div></div></div></div></div></div><div style="opacity:0;transform:translateY(20px)"><h3 class="mb-6 text-2xl font-serif font-medium text-foreground/80 pl-2 border-l-2 border-primary/20">2023</h3><div class="grid gap-4"><div><div data-slot="card" class="text-card-foreground flex flex-col gap-6 rounded-xl border py-6 shadow-sm group relative overflow-hidden border-border/50 bg-card/50 transition-all hover:border-primary/20 hover:shadow-lg hover:shadow-primary/5"><div class="absolute inset-0 bg-linear-to-br from-primary/5 via-transparent to-transparent opacity-0 transition-opacity group-hover:opacity-100"></div><div class="flex flex-col md:flex-row"><div class="relative w-full md:w-64 shrink-0 overflow-hidden md:border-r border-border/50 bg-muted/30"><button class="w-full h-full cursor-zoom-in focus:outline-none" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_39kt5fiutb_" data-state="closed"><div class="aspect-video md:h-full md:aspect-auto relative"><img alt="Figure from Context-Aware Task Handling in Resource-Constrained Robots with Virtualization" loading="lazy" decoding="async" data-nimg="fill" class="object-contain p-2 transition-transform duration-500 group-hover:scale-105" style="position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;color:transparent" src="/images/papers/context-aware-task-handling/featured.jpg"/></div></button></div><div class="flex-1 min-w-0 flex flex-col"><div data-slot="card-header" class="@container/card-header grid auto-rows-min grid-rows-[auto_auto] items-start gap-2 px-6 has-data-[slot=card-action]:grid-cols-[1fr_auto] [.border-b]:pb-6 pb-3"><div class="flex items-start justify-between gap-4"><div class="flex-1 space-y-2"><h3 class="font-serif text-xl font-medium leading-tight text-foreground group-hover:text-primary transition-colors"><a target="_blank" rel="noopener noreferrer" class="flex items-center gap-2 hover:underline decoration-primary/30 underline-offset-4" href="https://doi.org/10.1109/EDGE60047.2023.00047">Context-Aware Task Handling in Resource-Constrained Robots with Virtualization<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-arrow-up-right h-4 w-4 opacity-50" aria-hidden="true"><path d="M7 7h10v10"></path><path d="M7 17 17 7"></path></svg></a></h3><div class="flex flex-wrap items-center gap-2"><span data-slot="badge" class="inline-flex items-center justify-center rounded-full border px-2 py-0.5 text-xs w-fit whitespace-nowrap shrink-0 [&amp;&gt;svg]:size-3 gap-1 [&amp;&gt;svg]:pointer-events-none focus-visible:border-ring focus-visible:ring-ring/50 focus-visible:ring-[3px] aria-invalid:ring-destructive/20 dark:aria-invalid:ring-destructive/40 aria-invalid:border-destructive transition-[color,box-shadow] overflow-hidden border-transparent text-secondary-foreground [a&amp;]:hover:bg-secondary/90 bg-secondary/50 font-normal">IEEE International Conference on Edge Computing and Communications (EDGE)</span><span data-slot="badge" class="inline-flex items-center justify-center rounded-full border px-2 py-0.5 text-xs w-fit whitespace-nowrap shrink-0 [&amp;&gt;svg]:size-3 gap-1 [&amp;&gt;svg]:pointer-events-none focus-visible:border-ring focus-visible:ring-ring/50 focus-visible:ring-[3px] aria-invalid:ring-destructive/20 dark:aria-invalid:ring-destructive/40 aria-invalid:border-destructive transition-[color,box-shadow] overflow-hidden [a&amp;]:hover:bg-accent [a&amp;]:hover:text-accent-foreground font-normal text-muted-foreground">2023</span></div></div></div></div><div data-slot="card-content" class="px-6 pt-0 relative z-10 flex-1 flex flex-col justify-between"><div><p class="text-sm text-muted-foreground font-medium">Ramyad Hadidi, <b>Nima Shoghi</b>, Bahar Asgari, Hyesoon Kim</p><p class="mt-2 text-sm leading-relaxed text-foreground/80">Develops a fast context-aware technique that enables resource-constrained robots to handle multiple tasks simultaneously with improved timeliness, demonstrating a 42% speedup in execution time compared to standard scheduling approaches.</p></div><div class="mt-4 flex"><a target="_blank" rel="noopener noreferrer" class="inline-flex items-center gap-1.5 text-xs font-medium text-primary hover:text-primary/80 transition-colors" href="https://doi.org/10.1109/EDGE60047.2023.00047"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-file-text h-3.5 w-3.5" aria-hidden="true"><path d="M6 22a2 2 0 0 1-2-2V4a2 2 0 0 1 2-2h8a2.4 2.4 0 0 1 1.704.706l3.588 3.588A2.4 2.4 0 0 1 20 8v12a2 2 0 0 1-2 2z"></path><path d="M14 2v5a1 1 0 0 0 1 1h5"></path><path d="M10 9H8"></path><path d="M16 13H8"></path><path d="M16 17H8"></path></svg>Read Paper</a></div></div></div></div></div></div><div><div data-slot="card" class="text-card-foreground flex flex-col gap-6 rounded-xl border py-6 shadow-sm group relative overflow-hidden border-border/50 bg-card/50 transition-all hover:border-primary/20 hover:shadow-lg hover:shadow-primary/5"><div class="absolute inset-0 bg-linear-to-br from-primary/5 via-transparent to-transparent opacity-0 transition-opacity group-hover:opacity-100"></div><div class="flex flex-col md:flex-row"><div class="relative w-full md:w-64 shrink-0 overflow-hidden md:border-r border-border/50 bg-muted/30"><button class="w-full h-full cursor-zoom-in focus:outline-none" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_3akt5fiutb_" data-state="closed"><div class="aspect-video md:h-full md:aspect-auto relative"><img alt="Figure from The Open Catalyst 2022 (OC22) Dataset and Challenges for Oxide Electrocatalysts" loading="lazy" decoding="async" data-nimg="fill" class="object-contain p-2 transition-transform duration-500 group-hover:scale-105" style="position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;color:transparent" src="/images/papers/oc22/featured.jpg"/></div></button></div><div class="flex-1 min-w-0 flex flex-col"><div data-slot="card-header" class="@container/card-header grid auto-rows-min grid-rows-[auto_auto] items-start gap-2 px-6 has-data-[slot=card-action]:grid-cols-[1fr_auto] [.border-b]:pb-6 pb-3"><div class="flex items-start justify-between gap-4"><div class="flex-1 space-y-2"><h3 class="font-serif text-xl font-medium leading-tight text-foreground group-hover:text-primary transition-colors"><a target="_blank" rel="noopener noreferrer" class="flex items-center gap-2 hover:underline decoration-primary/30 underline-offset-4" href="https://doi.org/10.1021/acscatal.2c05426">The Open Catalyst 2022 (OC22) Dataset and Challenges for Oxide Electrocatalysts<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-arrow-up-right h-4 w-4 opacity-50" aria-hidden="true"><path d="M7 7h10v10"></path><path d="M7 17 17 7"></path></svg></a></h3><div class="flex flex-wrap items-center gap-2"><span data-slot="badge" class="inline-flex items-center justify-center rounded-full border px-2 py-0.5 text-xs w-fit whitespace-nowrap shrink-0 [&amp;&gt;svg]:size-3 gap-1 [&amp;&gt;svg]:pointer-events-none focus-visible:border-ring focus-visible:ring-ring/50 focus-visible:ring-[3px] aria-invalid:ring-destructive/20 dark:aria-invalid:ring-destructive/40 aria-invalid:border-destructive transition-[color,box-shadow] overflow-hidden border-transparent text-secondary-foreground [a&amp;]:hover:bg-secondary/90 bg-secondary/50 font-normal">ACS Catalysis 13 (5)</span><span data-slot="badge" class="inline-flex items-center justify-center rounded-full border px-2 py-0.5 text-xs w-fit whitespace-nowrap shrink-0 [&amp;&gt;svg]:size-3 gap-1 [&amp;&gt;svg]:pointer-events-none focus-visible:border-ring focus-visible:ring-ring/50 focus-visible:ring-[3px] aria-invalid:ring-destructive/20 dark:aria-invalid:ring-destructive/40 aria-invalid:border-destructive transition-[color,box-shadow] overflow-hidden [a&amp;]:hover:bg-accent [a&amp;]:hover:text-accent-foreground font-normal text-muted-foreground">2023</span><span data-slot="badge" class="inline-flex items-center justify-center rounded-full border px-2 py-0.5 text-xs font-medium w-fit whitespace-nowrap shrink-0 [&amp;&gt;svg]:size-3 gap-1 [&amp;&gt;svg]:pointer-events-none focus-visible:border-ring focus-visible:ring-ring/50 focus-visible:ring-[3px] aria-invalid:ring-destructive/20 dark:aria-invalid:ring-destructive/40 aria-invalid:border-destructive transition-[color,box-shadow] overflow-hidden [a&amp;]:hover:bg-primary/90 bg-primary/10 text-primary hover:bg-primary/20 border-primary/20">Featured</span></div></div></div></div><div data-slot="card-content" class="px-6 pt-0 relative z-10 flex-1 flex flex-col justify-between"><div><p class="text-sm text-muted-foreground font-medium">Richard Tran, Janice Lan, ..., <b>Nima Shoghi</b>, ..., C. Lawrence Zitnick</p><p class="mt-2 text-sm leading-relaxed text-foreground/80">Introduces the Open Catalyst 2022 (OC22) dataset, consisting of 62,331 DFT relaxations, to accelerate machine learning for oxide electrocatalysts and establish benchmarks for the field.</p></div><div class="mt-4 flex"><a target="_blank" rel="noopener noreferrer" class="inline-flex items-center gap-1.5 text-xs font-medium text-primary hover:text-primary/80 transition-colors" href="https://doi.org/10.1021/acscatal.2c05426"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-file-text h-3.5 w-3.5" aria-hidden="true"><path d="M6 22a2 2 0 0 1-2-2V4a2 2 0 0 1 2-2h8a2.4 2.4 0 0 1 1.704.706l3.588 3.588A2.4 2.4 0 0 1 20 8v12a2 2 0 0 1-2 2z"></path><path d="M14 2v5a1 1 0 0 0 1 1h5"></path><path d="M10 9H8"></path><path d="M16 13H8"></path><path d="M16 17H8"></path></svg>Read Paper</a></div></div></div></div></div></div></div></div><div style="opacity:0;transform:translateY(20px)"><h3 class="mb-6 text-2xl font-serif font-medium text-foreground/80 pl-2 border-l-2 border-primary/20">2022</h3><div class="grid gap-4"><div><div data-slot="card" class="text-card-foreground flex flex-col gap-6 rounded-xl border py-6 shadow-sm group relative overflow-hidden border-border/50 bg-card/50 transition-all hover:border-primary/20 hover:shadow-lg hover:shadow-primary/5"><div class="absolute inset-0 bg-linear-to-br from-primary/5 via-transparent to-transparent opacity-0 transition-opacity group-hover:opacity-100"></div><div class="flex flex-col md:flex-row"><div class="relative w-full md:w-64 shrink-0 overflow-hidden md:border-r border-border/50 bg-muted/30"><button class="w-full h-full cursor-zoom-in focus:outline-none" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_39l55fiutb_" data-state="closed"><div class="aspect-video md:h-full md:aspect-auto relative"><img alt="Figure from Transfer Learning Using Attentions Across Atomic Systems with Graph Neural Networks (TAAG)" loading="lazy" decoding="async" data-nimg="fill" class="object-contain p-2 transition-transform duration-500 group-hover:scale-105" style="position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;color:transparent" src="/images/papers/taag/featured.jpg"/></div></button></div><div class="flex-1 min-w-0 flex flex-col"><div data-slot="card-header" class="@container/card-header grid auto-rows-min grid-rows-[auto_auto] items-start gap-2 px-6 has-data-[slot=card-action]:grid-cols-[1fr_auto] [.border-b]:pb-6 pb-3"><div class="flex items-start justify-between gap-4"><div class="flex-1 space-y-2"><h3 class="font-serif text-xl font-medium leading-tight text-foreground group-hover:text-primary transition-colors"><a target="_blank" rel="noopener noreferrer" class="flex items-center gap-2 hover:underline decoration-primary/30 underline-offset-4" href="https://doi.org/10.1063/5.0088019">Transfer Learning Using Attentions Across Atomic Systems with Graph Neural Networks (TAAG)<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-arrow-up-right h-4 w-4 opacity-50" aria-hidden="true"><path d="M7 7h10v10"></path><path d="M7 17 17 7"></path></svg></a></h3><div class="flex flex-wrap items-center gap-2"><span data-slot="badge" class="inline-flex items-center justify-center rounded-full border px-2 py-0.5 text-xs w-fit whitespace-nowrap shrink-0 [&amp;&gt;svg]:size-3 gap-1 [&amp;&gt;svg]:pointer-events-none focus-visible:border-ring focus-visible:ring-ring/50 focus-visible:ring-[3px] aria-invalid:ring-destructive/20 dark:aria-invalid:ring-destructive/40 aria-invalid:border-destructive transition-[color,box-shadow] overflow-hidden border-transparent text-secondary-foreground [a&amp;]:hover:bg-secondary/90 bg-secondary/50 font-normal">The Journal of Chemical Physics 156 (18)</span><span data-slot="badge" class="inline-flex items-center justify-center rounded-full border px-2 py-0.5 text-xs w-fit whitespace-nowrap shrink-0 [&amp;&gt;svg]:size-3 gap-1 [&amp;&gt;svg]:pointer-events-none focus-visible:border-ring focus-visible:ring-ring/50 focus-visible:ring-[3px] aria-invalid:ring-destructive/20 dark:aria-invalid:ring-destructive/40 aria-invalid:border-destructive transition-[color,box-shadow] overflow-hidden [a&amp;]:hover:bg-accent [a&amp;]:hover:text-accent-foreground font-normal text-muted-foreground">2022</span></div></div></div></div><div data-slot="card-content" class="px-6 pt-0 relative z-10 flex-1 flex flex-col justify-between"><div><p class="text-sm text-muted-foreground font-medium">Adeesh Kolluru, <b>Nima Shoghi</b>, Muhammed Shuaibi, Siddharth Goyal, Abhishek Das, C. Lawrence Zitnick, Zachary Ulissi</p><p class="mt-2 text-sm leading-relaxed text-foreground/80">Introduces a transfer learning approach using Graph Neural Networks to generalize models across domains in molecular and catalyst discovery, reducing the need for large, domain-specific datasets.</p></div><div class="mt-4 flex"><a target="_blank" rel="noopener noreferrer" class="inline-flex items-center gap-1.5 text-xs font-medium text-primary hover:text-primary/80 transition-colors" href="https://doi.org/10.1063/5.0088019"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-file-text h-3.5 w-3.5" aria-hidden="true"><path d="M6 22a2 2 0 0 1-2-2V4a2 2 0 0 1 2-2h8a2.4 2.4 0 0 1 1.704.706l3.588 3.588A2.4 2.4 0 0 1 20 8v12a2 2 0 0 1-2 2z"></path><path d="M14 2v5a1 1 0 0 0 1 1h5"></path><path d="M10 9H8"></path><path d="M16 13H8"></path><path d="M16 17H8"></path></svg>Read Paper</a></div></div></div></div></div></div><div><div data-slot="card" class="text-card-foreground flex flex-col gap-6 rounded-xl border py-6 shadow-sm group relative overflow-hidden border-border/50 bg-card/50 transition-all hover:border-primary/20 hover:shadow-lg hover:shadow-primary/5"><div class="absolute inset-0 bg-linear-to-br from-primary/5 via-transparent to-transparent opacity-0 transition-opacity group-hover:opacity-100"></div><div class="flex flex-col md:flex-row"><div class="relative w-full md:w-64 shrink-0 overflow-hidden md:border-r border-border/50 bg-muted/30"><button class="w-full h-full cursor-zoom-in focus:outline-none" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_3al55fiutb_" data-state="closed"><div class="aspect-video md:h-full md:aspect-auto relative"><img alt="Figure from Open Challenges in Developing Generalizable Large-Scale Machine-Learning Models for Catalyst Discovery" loading="lazy" decoding="async" data-nimg="fill" class="object-contain p-2 transition-transform duration-500 group-hover:scale-105" style="position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;color:transparent" src="/images/papers/fair-open-challenges-perspective/featured.jpg"/></div></button></div><div class="flex-1 min-w-0 flex flex-col"><div data-slot="card-header" class="@container/card-header grid auto-rows-min grid-rows-[auto_auto] items-start gap-2 px-6 has-data-[slot=card-action]:grid-cols-[1fr_auto] [.border-b]:pb-6 pb-3"><div class="flex items-start justify-between gap-4"><div class="flex-1 space-y-2"><h3 class="font-serif text-xl font-medium leading-tight text-foreground group-hover:text-primary transition-colors"><a target="_blank" rel="noopener noreferrer" class="flex items-center gap-2 hover:underline decoration-primary/30 underline-offset-4" href="https://doi.org/10.1021/acscatal.2c02291">Open Challenges in Developing Generalizable Large-Scale Machine-Learning Models for Catalyst Discovery<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-arrow-up-right h-4 w-4 opacity-50" aria-hidden="true"><path d="M7 7h10v10"></path><path d="M7 17 17 7"></path></svg></a></h3><div class="flex flex-wrap items-center gap-2"><span data-slot="badge" class="inline-flex items-center justify-center rounded-full border px-2 py-0.5 text-xs w-fit whitespace-nowrap shrink-0 [&amp;&gt;svg]:size-3 gap-1 [&amp;&gt;svg]:pointer-events-none focus-visible:border-ring focus-visible:ring-ring/50 focus-visible:ring-[3px] aria-invalid:ring-destructive/20 dark:aria-invalid:ring-destructive/40 aria-invalid:border-destructive transition-[color,box-shadow] overflow-hidden border-transparent text-secondary-foreground [a&amp;]:hover:bg-secondary/90 bg-secondary/50 font-normal">ACS Catalysis 12 (14)</span><span data-slot="badge" class="inline-flex items-center justify-center rounded-full border px-2 py-0.5 text-xs w-fit whitespace-nowrap shrink-0 [&amp;&gt;svg]:size-3 gap-1 [&amp;&gt;svg]:pointer-events-none focus-visible:border-ring focus-visible:ring-ring/50 focus-visible:ring-[3px] aria-invalid:ring-destructive/20 dark:aria-invalid:ring-destructive/40 aria-invalid:border-destructive transition-[color,box-shadow] overflow-hidden [a&amp;]:hover:bg-accent [a&amp;]:hover:text-accent-foreground font-normal text-muted-foreground">2022</span></div></div></div></div><div data-slot="card-content" class="px-6 pt-0 relative z-10 flex-1 flex flex-col justify-between"><div><p class="text-sm text-muted-foreground font-medium">Adeesh Kolluru, Muhammed Shuaibi, Aini Palizhati, <b>Nima Shoghi</b>, Abhishek Das, Brandon Wood, C. Lawrence Zitnick, John Kitchin, Zachary Ulissi</p><p class="mt-2 text-sm leading-relaxed text-foreground/80">Discusses the challenges and potential of developing generalizable machine learning models for catalyst discovery, highlighting the importance of large-scale datasets like the Open Catalyst 2020 Data set (OC20).</p></div><div class="mt-4 flex"><a target="_blank" rel="noopener noreferrer" class="inline-flex items-center gap-1.5 text-xs font-medium text-primary hover:text-primary/80 transition-colors" href="https://doi.org/10.1021/acscatal.2c02291"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-file-text h-3.5 w-3.5" aria-hidden="true"><path d="M6 22a2 2 0 0 1-2-2V4a2 2 0 0 1 2-2h8a2.4 2.4 0 0 1 1.704.706l3.588 3.588A2.4 2.4 0 0 1 20 8v12a2 2 0 0 1-2 2z"></path><path d="M14 2v5a1 1 0 0 0 1 1h5"></path><path d="M10 9H8"></path><path d="M16 13H8"></path><path d="M16 17H8"></path></svg>Read Paper</a></div></div></div></div></div></div></div></div><div style="opacity:0;transform:translateY(20px)"><h3 class="mb-6 text-2xl font-serif font-medium text-foreground/80 pl-2 border-l-2 border-primary/20">2021</h3><div class="grid gap-4"><div><div data-slot="card" class="text-card-foreground flex flex-col gap-6 rounded-xl border py-6 shadow-sm group relative overflow-hidden border-border/50 bg-card/50 transition-all hover:border-primary/20 hover:shadow-lg hover:shadow-primary/5"><div class="absolute inset-0 bg-linear-to-br from-primary/5 via-transparent to-transparent opacity-0 transition-opacity group-hover:opacity-100"></div><div class="flex flex-col md:flex-row"><div class="relative w-full md:w-64 shrink-0 overflow-hidden md:border-r border-border/50 bg-muted/30"><button class="w-full h-full cursor-zoom-in focus:outline-none" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_39ld5fiutb_" data-state="closed"><div class="aspect-video md:h-full md:aspect-auto relative"><img alt="Figure from SmaQ: Smart Quantization for DNN Training by Exploiting Value Clustering" loading="lazy" decoding="async" data-nimg="fill" class="object-contain p-2 transition-transform duration-500 group-hover:scale-105" style="position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;color:transparent" src="/images/papers/smaq/featured.jpg"/></div></button></div><div class="flex-1 min-w-0 flex flex-col"><div data-slot="card-header" class="@container/card-header grid auto-rows-min grid-rows-[auto_auto] items-start gap-2 px-6 has-data-[slot=card-action]:grid-cols-[1fr_auto] [.border-b]:pb-6 pb-3"><div class="flex items-start justify-between gap-4"><div class="flex-1 space-y-2"><h3 class="font-serif text-xl font-medium leading-tight text-foreground group-hover:text-primary transition-colors"><a target="_blank" rel="noopener noreferrer" class="flex items-center gap-2 hover:underline decoration-primary/30 underline-offset-4" href="https://doi.org/10.1109/LCA.2021.3108505">SmaQ: Smart Quantization for DNN Training by Exploiting Value Clustering<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-arrow-up-right h-4 w-4 opacity-50" aria-hidden="true"><path d="M7 7h10v10"></path><path d="M7 17 17 7"></path></svg></a></h3><div class="flex flex-wrap items-center gap-2"><span data-slot="badge" class="inline-flex items-center justify-center rounded-full border px-2 py-0.5 text-xs w-fit whitespace-nowrap shrink-0 [&amp;&gt;svg]:size-3 gap-1 [&amp;&gt;svg]:pointer-events-none focus-visible:border-ring focus-visible:ring-ring/50 focus-visible:ring-[3px] aria-invalid:ring-destructive/20 dark:aria-invalid:ring-destructive/40 aria-invalid:border-destructive transition-[color,box-shadow] overflow-hidden border-transparent text-secondary-foreground [a&amp;]:hover:bg-secondary/90 bg-secondary/50 font-normal">IEEE Computer Architecture Letters 20 (2)</span><span data-slot="badge" class="inline-flex items-center justify-center rounded-full border px-2 py-0.5 text-xs w-fit whitespace-nowrap shrink-0 [&amp;&gt;svg]:size-3 gap-1 [&amp;&gt;svg]:pointer-events-none focus-visible:border-ring focus-visible:ring-ring/50 focus-visible:ring-[3px] aria-invalid:ring-destructive/20 dark:aria-invalid:ring-destructive/40 aria-invalid:border-destructive transition-[color,box-shadow] overflow-hidden [a&amp;]:hover:bg-accent [a&amp;]:hover:text-accent-foreground font-normal text-muted-foreground">2021</span></div></div></div></div><div data-slot="card-content" class="px-6 pt-0 relative z-10 flex-1 flex flex-col justify-between"><div><p class="text-sm text-muted-foreground font-medium"><b>Nima Shoghi</b>, Andrei Bersatti, Moinuddin Qureshi, Hyesoon Kim</p><p class="mt-2 text-sm leading-relaxed text-foreground/80">Introduces SmaQ, a quantization scheme that leverages the normal distribution of neural network data structures to efficiently quantize them, addressing the memory bottleneck in single-machine training of deep networks.</p></div><div class="mt-4 flex"><a target="_blank" rel="noopener noreferrer" class="inline-flex items-center gap-1.5 text-xs font-medium text-primary hover:text-primary/80 transition-colors" href="https://doi.org/10.1109/LCA.2021.3108505"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-file-text h-3.5 w-3.5" aria-hidden="true"><path d="M6 22a2 2 0 0 1-2-2V4a2 2 0 0 1 2-2h8a2.4 2.4 0 0 1 1.704.706l3.588 3.588A2.4 2.4 0 0 1 20 8v12a2 2 0 0 1-2 2z"></path><path d="M14 2v5a1 1 0 0 0 1 1h5"></path><path d="M10 9H8"></path><path d="M16 13H8"></path><path d="M16 17H8"></path></svg>Read Paper</a></div></div></div></div></div></div><div><div data-slot="card" class="text-card-foreground flex flex-col gap-6 rounded-xl border py-6 shadow-sm group relative overflow-hidden border-border/50 bg-card/50 transition-all hover:border-primary/20 hover:shadow-lg hover:shadow-primary/5"><div class="absolute inset-0 bg-linear-to-br from-primary/5 via-transparent to-transparent opacity-0 transition-opacity group-hover:opacity-100"></div><div class="flex flex-col md:flex-row"><div class="relative w-full md:w-64 shrink-0 overflow-hidden md:border-r border-border/50 bg-muted/30"><button class="w-full h-full cursor-zoom-in focus:outline-none" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_3ald5fiutb_" data-state="closed"><div class="aspect-video md:h-full md:aspect-auto relative"><img alt="Figure from Quantifying the Design-Space Tradeoffs in Autonomous Drones" loading="lazy" decoding="async" data-nimg="fill" class="object-contain p-2 transition-transform duration-500 group-hover:scale-105" style="position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;color:transparent" src="/images/papers/drone-design-space-tradeoffs/featured.jpg"/></div></button></div><div class="flex-1 min-w-0 flex flex-col"><div data-slot="card-header" class="@container/card-header grid auto-rows-min grid-rows-[auto_auto] items-start gap-2 px-6 has-data-[slot=card-action]:grid-cols-[1fr_auto] [.border-b]:pb-6 pb-3"><div class="flex items-start justify-between gap-4"><div class="flex-1 space-y-2"><h3 class="font-serif text-xl font-medium leading-tight text-foreground group-hover:text-primary transition-colors"><a target="_blank" rel="noopener noreferrer" class="flex items-center gap-2 hover:underline decoration-primary/30 underline-offset-4" href="https://doi.org/10.1145/3445814.3446721">Quantifying the Design-Space Tradeoffs in Autonomous Drones<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-arrow-up-right h-4 w-4 opacity-50" aria-hidden="true"><path d="M7 7h10v10"></path><path d="M7 17 17 7"></path></svg></a></h3><div class="flex flex-wrap items-center gap-2"><span data-slot="badge" class="inline-flex items-center justify-center rounded-full border px-2 py-0.5 text-xs w-fit whitespace-nowrap shrink-0 [&amp;&gt;svg]:size-3 gap-1 [&amp;&gt;svg]:pointer-events-none focus-visible:border-ring focus-visible:ring-ring/50 focus-visible:ring-[3px] aria-invalid:ring-destructive/20 dark:aria-invalid:ring-destructive/40 aria-invalid:border-destructive transition-[color,box-shadow] overflow-hidden border-transparent text-secondary-foreground [a&amp;]:hover:bg-secondary/90 bg-secondary/50 font-normal">Proceedings of the 26th ACM International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS)</span><span data-slot="badge" class="inline-flex items-center justify-center rounded-full border px-2 py-0.5 text-xs w-fit whitespace-nowrap shrink-0 [&amp;&gt;svg]:size-3 gap-1 [&amp;&gt;svg]:pointer-events-none focus-visible:border-ring focus-visible:ring-ring/50 focus-visible:ring-[3px] aria-invalid:ring-destructive/20 dark:aria-invalid:ring-destructive/40 aria-invalid:border-destructive transition-[color,box-shadow] overflow-hidden [a&amp;]:hover:bg-accent [a&amp;]:hover:text-accent-foreground font-normal text-muted-foreground">2021</span></div></div></div></div><div data-slot="card-content" class="px-6 pt-0 relative z-10 flex-1 flex flex-col justify-between"><div><p class="text-sm text-muted-foreground font-medium">Ramyad Hadidi, Bahar Asgari, Sam Jijina, Adriana Amyette, <b>Nima Shoghi</b>, Hyesoon Kim</p><p class="mt-2 text-sm leading-relaxed text-foreground/80">Formalizes the subsystems of autonomous drones and quantifies the complex tradeoffs in their design space to enable optimized solutions for diverse applications.</p></div><div class="mt-4 flex"><a target="_blank" rel="noopener noreferrer" class="inline-flex items-center gap-1.5 text-xs font-medium text-primary hover:text-primary/80 transition-colors" href="https://doi.org/10.1145/3445814.3446721"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-file-text h-3.5 w-3.5" aria-hidden="true"><path d="M6 22a2 2 0 0 1-2-2V4a2 2 0 0 1 2-2h8a2.4 2.4 0 0 1 1.704.706l3.588 3.588A2.4 2.4 0 0 1 20 8v12a2 2 0 0 1-2 2z"></path><path d="M14 2v5a1 1 0 0 0 1 1h5"></path><path d="M10 9H8"></path><path d="M16 13H8"></path><path d="M16 17H8"></path></svg>Read Paper</a></div></div></div></div></div></div></div></div><div style="opacity:0;transform:translateY(20px)"><h3 class="mb-6 text-2xl font-serif font-medium text-foreground/80 pl-2 border-l-2 border-primary/20">2020</h3><div class="grid gap-4"><div><div data-slot="card" class="text-card-foreground flex flex-col gap-6 rounded-xl border py-6 shadow-sm group relative overflow-hidden border-border/50 bg-card/50 transition-all hover:border-primary/20 hover:shadow-lg hover:shadow-primary/5"><div class="absolute inset-0 bg-linear-to-br from-primary/5 via-transparent to-transparent opacity-0 transition-opacity group-hover:opacity-100"></div><div class="flex flex-col md:flex-row"><div class="relative w-full md:w-64 shrink-0 overflow-hidden md:border-r border-border/50 bg-muted/30"><button class="w-full h-full cursor-zoom-in focus:outline-none" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_6hll5fiutb_" data-state="closed"><div class="aspect-video md:h-full md:aspect-auto relative"><img alt="Figure from Neural Network Weight Compression with NNW-BDI" loading="lazy" decoding="async" data-nimg="fill" class="object-contain p-2 transition-transform duration-500 group-hover:scale-105" style="position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;color:transparent" src="/images/papers/nnw-bdi/featured.jpg"/></div></button></div><div class="flex-1 min-w-0 flex flex-col"><div data-slot="card-header" class="@container/card-header grid auto-rows-min grid-rows-[auto_auto] items-start gap-2 px-6 has-data-[slot=card-action]:grid-cols-[1fr_auto] [.border-b]:pb-6 pb-3"><div class="flex items-start justify-between gap-4"><div class="flex-1 space-y-2"><h3 class="font-serif text-xl font-medium leading-tight text-foreground group-hover:text-primary transition-colors"><a target="_blank" rel="noopener noreferrer" class="flex items-center gap-2 hover:underline decoration-primary/30 underline-offset-4" href="https://doi.org/10.1145/3422575.3422805">Neural Network Weight Compression with NNW-BDI<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-arrow-up-right h-4 w-4 opacity-50" aria-hidden="true"><path d="M7 7h10v10"></path><path d="M7 17 17 7"></path></svg></a></h3><div class="flex flex-wrap items-center gap-2"><span data-slot="badge" class="inline-flex items-center justify-center rounded-full border px-2 py-0.5 text-xs w-fit whitespace-nowrap shrink-0 [&amp;&gt;svg]:size-3 gap-1 [&amp;&gt;svg]:pointer-events-none focus-visible:border-ring focus-visible:ring-ring/50 focus-visible:ring-[3px] aria-invalid:ring-destructive/20 dark:aria-invalid:ring-destructive/40 aria-invalid:border-destructive transition-[color,box-shadow] overflow-hidden border-transparent text-secondary-foreground [a&amp;]:hover:bg-secondary/90 bg-secondary/50 font-normal">Proceedings of the International Symposium on Memory Systems (MemSys)</span><span data-slot="badge" class="inline-flex items-center justify-center rounded-full border px-2 py-0.5 text-xs w-fit whitespace-nowrap shrink-0 [&amp;&gt;svg]:size-3 gap-1 [&amp;&gt;svg]:pointer-events-none focus-visible:border-ring focus-visible:ring-ring/50 focus-visible:ring-[3px] aria-invalid:ring-destructive/20 dark:aria-invalid:ring-destructive/40 aria-invalid:border-destructive transition-[color,box-shadow] overflow-hidden [a&amp;]:hover:bg-accent [a&amp;]:hover:text-accent-foreground font-normal text-muted-foreground">2020</span></div></div></div></div><div data-slot="card-content" class="px-6 pt-0 relative z-10 flex-1 flex flex-col justify-between"><div><p class="text-sm text-muted-foreground font-medium"><b>Nima Shoghi</b>, Andrei Bersatti, Hyesoon Kim</p><p class="mt-2 text-sm leading-relaxed text-foreground/80">Introduces NNW-BDI, a neural network weight compression scheme that reduces memory usage by up to 85% without sacrificing inference accuracy on an MNIST classification task.</p></div><div class="mt-4 flex"><a target="_blank" rel="noopener noreferrer" class="inline-flex items-center gap-1.5 text-xs font-medium text-primary hover:text-primary/80 transition-colors" href="https://doi.org/10.1145/3422575.3422805"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-file-text h-3.5 w-3.5" aria-hidden="true"><path d="M6 22a2 2 0 0 1-2-2V4a2 2 0 0 1 2-2h8a2.4 2.4 0 0 1 1.704.706l3.588 3.588A2.4 2.4 0 0 1 20 8v12a2 2 0 0 1-2 2z"></path><path d="M14 2v5a1 1 0 0 0 1 1h5"></path><path d="M10 9H8"></path><path d="M16 13H8"></path><path d="M16 17H8"></path></svg>Read Paper</a></div></div></div></div></div></div><div><div data-slot="card" class="text-card-foreground flex flex-col gap-6 rounded-xl border py-6 shadow-sm group relative overflow-hidden border-border/50 bg-card/50 transition-all hover:border-primary/20 hover:shadow-lg hover:shadow-primary/5"><div class="absolute inset-0 bg-linear-to-br from-primary/5 via-transparent to-transparent opacity-0 transition-opacity group-hover:opacity-100"></div><div class="flex flex-col md:flex-row"><div class="relative w-full md:w-64 shrink-0 overflow-hidden md:border-r border-border/50 bg-muted/30"><button class="w-full h-full cursor-zoom-in focus:outline-none" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_6ill5fiutb_" data-state="closed"><div class="aspect-video md:h-full md:aspect-auto relative"><img alt="Figure from Pisces: Power-Aware Implementation of SLAM by Customizing Efficient Sparse Algebra" loading="lazy" decoding="async" data-nimg="fill" class="object-contain p-2 transition-transform duration-500 group-hover:scale-105" style="position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;color:transparent" src="/images/papers/pisces/featured.jpg"/></div></button></div><div class="flex-1 min-w-0 flex flex-col"><div data-slot="card-header" class="@container/card-header grid auto-rows-min grid-rows-[auto_auto] items-start gap-2 px-6 has-data-[slot=card-action]:grid-cols-[1fr_auto] [.border-b]:pb-6 pb-3"><div class="flex items-start justify-between gap-4"><div class="flex-1 space-y-2"><h3 class="font-serif text-xl font-medium leading-tight text-foreground group-hover:text-primary transition-colors"><a target="_blank" rel="noopener noreferrer" class="flex items-center gap-2 hover:underline decoration-primary/30 underline-offset-4" href="https://doi.org/10.1109/DAC18072.2020.9218550">Pisces: Power-Aware Implementation of SLAM by Customizing Efficient Sparse Algebra<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-arrow-up-right h-4 w-4 opacity-50" aria-hidden="true"><path d="M7 7h10v10"></path><path d="M7 17 17 7"></path></svg></a></h3><div class="flex flex-wrap items-center gap-2"><span data-slot="badge" class="inline-flex items-center justify-center rounded-full border px-2 py-0.5 text-xs w-fit whitespace-nowrap shrink-0 [&amp;&gt;svg]:size-3 gap-1 [&amp;&gt;svg]:pointer-events-none focus-visible:border-ring focus-visible:ring-ring/50 focus-visible:ring-[3px] aria-invalid:ring-destructive/20 dark:aria-invalid:ring-destructive/40 aria-invalid:border-destructive transition-[color,box-shadow] overflow-hidden border-transparent text-secondary-foreground [a&amp;]:hover:bg-secondary/90 bg-secondary/50 font-normal">2020 57th ACM/IEEE Design Automation Conference (DAC)</span><span data-slot="badge" class="inline-flex items-center justify-center rounded-full border px-2 py-0.5 text-xs w-fit whitespace-nowrap shrink-0 [&amp;&gt;svg]:size-3 gap-1 [&amp;&gt;svg]:pointer-events-none focus-visible:border-ring focus-visible:ring-ring/50 focus-visible:ring-[3px] aria-invalid:ring-destructive/20 dark:aria-invalid:ring-destructive/40 aria-invalid:border-destructive transition-[color,box-shadow] overflow-hidden [a&amp;]:hover:bg-accent [a&amp;]:hover:text-accent-foreground font-normal text-muted-foreground">2020</span></div></div></div></div><div data-slot="card-content" class="px-6 pt-0 relative z-10 flex-1 flex flex-col justify-between"><div><p class="text-sm text-muted-foreground font-medium">Bahar Asgari, Ramyad Hadidi, <b>Nima Shoghi</b>, Hyesoon Kim</p><p class="mt-2 text-sm leading-relaxed text-foreground/80">Introduces Pisces, a power-aware SLAM implementation that consumes 2.5x less power and executes 7.4x faster than the state of the art by customizing efficient sparse algebra on FPGAs.</p></div><div class="mt-4 flex"><a target="_blank" rel="noopener noreferrer" class="inline-flex items-center gap-1.5 text-xs font-medium text-primary hover:text-primary/80 transition-colors" href="https://doi.org/10.1109/DAC18072.2020.9218550"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-file-text h-3.5 w-3.5" aria-hidden="true"><path d="M6 22a2 2 0 0 1-2-2V4a2 2 0 0 1 2-2h8a2.4 2.4 0 0 1 1.704.706l3.588 3.588A2.4 2.4 0 0 1 20 8v12a2 2 0 0 1-2 2z"></path><path d="M14 2v5a1 1 0 0 0 1 1h5"></path><path d="M10 9H8"></path><path d="M16 13H8"></path><path d="M16 17H8"></path></svg>Read Paper</a></div></div></div></div></div></div><div><div data-slot="card" class="text-card-foreground flex flex-col gap-6 rounded-xl border py-6 shadow-sm group relative overflow-hidden border-border/50 bg-card/50 transition-all hover:border-primary/20 hover:shadow-lg hover:shadow-primary/5"><div class="absolute inset-0 bg-linear-to-br from-primary/5 via-transparent to-transparent opacity-0 transition-opacity group-hover:opacity-100"></div><div class="flex flex-col md:flex-row"><div class="relative w-full md:w-64 shrink-0 overflow-hidden md:border-r border-border/50 bg-muted/30"><button class="w-full h-full cursor-zoom-in focus:outline-none" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_6jll5fiutb_" data-state="closed"><div class="aspect-video md:h-full md:aspect-auto relative"><img alt="Figure from Secure Location-Aware Authentication and Communication for Intelligent Transportation Systems" loading="lazy" decoding="async" data-nimg="fill" class="object-contain p-2 transition-transform duration-500 group-hover:scale-105" style="position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;color:transparent" src="/images/papers/secure-location-aware-authentication/featured.jpg"/></div></button></div><div class="flex-1 min-w-0 flex flex-col"><div data-slot="card-header" class="@container/card-header grid auto-rows-min grid-rows-[auto_auto] items-start gap-2 px-6 has-data-[slot=card-action]:grid-cols-[1fr_auto] [.border-b]:pb-6 pb-3"><div class="flex items-start justify-between gap-4"><div class="flex-1 space-y-2"><h3 class="font-serif text-xl font-medium leading-tight text-foreground group-hover:text-primary transition-colors"><a target="_blank" rel="noopener noreferrer" class="flex items-center gap-2 hover:underline decoration-primary/30 underline-offset-4" href="https://arxiv.org/abs/2011.08936">Secure Location-Aware Authentication and Communication for Intelligent Transportation Systems<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-arrow-up-right h-4 w-4 opacity-50" aria-hidden="true"><path d="M7 7h10v10"></path><path d="M7 17 17 7"></path></svg></a></h3><div class="flex flex-wrap items-center gap-2"><span data-slot="badge" class="inline-flex items-center justify-center rounded-full border px-2 py-0.5 text-xs w-fit whitespace-nowrap shrink-0 [&amp;&gt;svg]:size-3 gap-1 [&amp;&gt;svg]:pointer-events-none focus-visible:border-ring focus-visible:ring-ring/50 focus-visible:ring-[3px] aria-invalid:ring-destructive/20 dark:aria-invalid:ring-destructive/40 aria-invalid:border-destructive transition-[color,box-shadow] overflow-hidden border-transparent text-secondary-foreground [a&amp;]:hover:bg-secondary/90 bg-secondary/50 font-normal">arXiv preprint</span><span data-slot="badge" class="inline-flex items-center justify-center rounded-full border px-2 py-0.5 text-xs w-fit whitespace-nowrap shrink-0 [&amp;&gt;svg]:size-3 gap-1 [&amp;&gt;svg]:pointer-events-none focus-visible:border-ring focus-visible:ring-ring/50 focus-visible:ring-[3px] aria-invalid:ring-destructive/20 dark:aria-invalid:ring-destructive/40 aria-invalid:border-destructive transition-[color,box-shadow] overflow-hidden [a&amp;]:hover:bg-accent [a&amp;]:hover:text-accent-foreground font-normal text-muted-foreground">2020</span></div></div></div></div><div data-slot="card-content" class="px-6 pt-0 relative z-10 flex-1 flex flex-col justify-between"><div><p class="text-sm text-muted-foreground font-medium"><b>Nima Shoghi</b>, Ramyad Hadidi, Lee Jaewon, Jun Chen, Arthur Siqueria, Rahul Rajan, Shaan Dhawan, Pooya Shoghi, Hyesoon Kim</p><p class="mt-2 text-sm leading-relaxed text-foreground/80">Introduces a scalable, infrastructure-independent, location-aware authentication protocol for intelligent transportation systems, providing trustworthy communication and efficient sender localization using visual authentication beacons.</p></div><div class="mt-4 flex"><a target="_blank" rel="noopener noreferrer" class="inline-flex items-center gap-1.5 text-xs font-medium text-primary hover:text-primary/80 transition-colors" href="https://arxiv.org/abs/2011.08936"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-file-text h-3.5 w-3.5" aria-hidden="true"><path d="M6 22a2 2 0 0 1-2-2V4a2 2 0 0 1 2-2h8a2.4 2.4 0 0 1 1.704.706l3.588 3.588A2.4 2.4 0 0 1 20 8v12a2 2 0 0 1-2 2z"></path><path d="M14 2v5a1 1 0 0 0 1 1h5"></path><path d="M10 9H8"></path><path d="M16 13H8"></path><path d="M16 17H8"></path></svg>Read Paper</a></div></div></div></div></div></div><div><div data-slot="card" class="text-card-foreground flex flex-col gap-6 rounded-xl border py-6 shadow-sm group relative overflow-hidden border-border/50 bg-card/50 transition-all hover:border-primary/20 hover:shadow-lg hover:shadow-primary/5"><div class="absolute inset-0 bg-linear-to-br from-primary/5 via-transparent to-transparent opacity-0 transition-opacity group-hover:opacity-100"></div><div class="flex flex-col md:flex-row"><div class="relative w-full md:w-64 shrink-0 overflow-hidden md:border-r border-border/50 bg-muted/30"><button class="w-full h-full cursor-zoom-in focus:outline-none" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_6kll5fiutb_" data-state="closed"><div class="aspect-video md:h-full md:aspect-auto relative"><img alt="Figure from Understanding the Software and Hardware Stacks of a General-Purpose Cognitive Drone" loading="lazy" decoding="async" data-nimg="fill" class="object-contain p-2 transition-transform duration-500 group-hover:scale-105" style="position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;color:transparent" src="/images/papers/sam_2020_drone/featured.jpg"/></div></button></div><div class="flex-1 min-w-0 flex flex-col"><div data-slot="card-header" class="@container/card-header grid auto-rows-min grid-rows-[auto_auto] items-start gap-2 px-6 has-data-[slot=card-action]:grid-cols-[1fr_auto] [.border-b]:pb-6 pb-3"><div class="flex items-start justify-between gap-4"><div class="flex-1 space-y-2"><h3 class="font-serif text-xl font-medium leading-tight text-foreground group-hover:text-primary transition-colors"><a target="_blank" rel="noopener noreferrer" class="flex items-center gap-2 hover:underline decoration-primary/30 underline-offset-4" href="https://doi.org/10.1109/ISPASS48437.2020.00029">Understanding the Software and Hardware Stacks of a General-Purpose Cognitive Drone<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-arrow-up-right h-4 w-4 opacity-50" aria-hidden="true"><path d="M7 7h10v10"></path><path d="M7 17 17 7"></path></svg></a></h3><div class="flex flex-wrap items-center gap-2"><span data-slot="badge" class="inline-flex items-center justify-center rounded-full border px-2 py-0.5 text-xs w-fit whitespace-nowrap shrink-0 [&amp;&gt;svg]:size-3 gap-1 [&amp;&gt;svg]:pointer-events-none focus-visible:border-ring focus-visible:ring-ring/50 focus-visible:ring-[3px] aria-invalid:ring-destructive/20 dark:aria-invalid:ring-destructive/40 aria-invalid:border-destructive transition-[color,box-shadow] overflow-hidden border-transparent text-secondary-foreground [a&amp;]:hover:bg-secondary/90 bg-secondary/50 font-normal">2020 IEEE International Symposium on Performance Analysis of Systems and Software (ISPASS)</span><span data-slot="badge" class="inline-flex items-center justify-center rounded-full border px-2 py-0.5 text-xs w-fit whitespace-nowrap shrink-0 [&amp;&gt;svg]:size-3 gap-1 [&amp;&gt;svg]:pointer-events-none focus-visible:border-ring focus-visible:ring-ring/50 focus-visible:ring-[3px] aria-invalid:ring-destructive/20 dark:aria-invalid:ring-destructive/40 aria-invalid:border-destructive transition-[color,box-shadow] overflow-hidden [a&amp;]:hover:bg-accent [a&amp;]:hover:text-accent-foreground font-normal text-muted-foreground">2020</span></div></div></div></div><div data-slot="card-content" class="px-6 pt-0 relative z-10 flex-1 flex flex-col justify-between"><div><p class="text-sm text-muted-foreground font-medium">Sam Jijina, Adriana Amyette, <b>Nima Shoghi</b>, Ramyad Hadidi, Hyesoon Kim</p><p class="mt-2 text-sm leading-relaxed text-foreground/80">Conducts an in-depth analysis of the hardware and software components of autonomous drones, characterizing the performance of the ArduCopter flight stack and providing insights to optimize flight controllers and increase drone range.</p></div><div class="mt-4 flex"><a target="_blank" rel="noopener noreferrer" class="inline-flex items-center gap-1.5 text-xs font-medium text-primary hover:text-primary/80 transition-colors" href="https://doi.org/10.1109/ISPASS48437.2020.00029"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-file-text h-3.5 w-3.5" aria-hidden="true"><path d="M6 22a2 2 0 0 1-2-2V4a2 2 0 0 1 2-2h8a2.4 2.4 0 0 1 1.704.706l3.588 3.588A2.4 2.4 0 0 1 20 8v12a2 2 0 0 1-2 2z"></path><path d="M14 2v5a1 1 0 0 0 1 1h5"></path><path d="M10 9H8"></path><path d="M16 13H8"></path><path d="M16 17H8"></path></svg>Read Paper</a></div></div></div></div></div></div></div></div><div style="opacity:0;transform:translateY(20px)"><h3 class="mb-6 text-2xl font-serif font-medium text-foreground/80 pl-2 border-l-2 border-primary/20">2019</h3><div class="grid gap-4"><div><div data-slot="card" class="text-card-foreground flex flex-col gap-6 rounded-xl border py-6 shadow-sm group relative overflow-hidden border-border/50 bg-card/50 transition-all hover:border-primary/20 hover:shadow-lg hover:shadow-primary/5"><div class="absolute inset-0 bg-linear-to-br from-primary/5 via-transparent to-transparent opacity-0 transition-opacity group-hover:opacity-100"></div><div class="flex flex-col md:flex-row"><div class="relative w-full md:w-64 shrink-0 overflow-hidden md:border-r border-border/50 bg-muted/30"><button class="w-full h-full cursor-zoom-in focus:outline-none" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-_R_1llt5fiutb_" data-state="closed"><div class="aspect-video md:h-full md:aspect-auto relative"><img alt="Figure from SLAM Performance on Embedded Robots" loading="lazy" decoding="async" data-nimg="fill" class="object-contain p-2 transition-transform duration-500 group-hover:scale-105" style="position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;color:transparent" src="/images/papers/slam-performance-emedded-robots/featured.jpg"/></div></button></div><div class="flex-1 min-w-0 flex flex-col"><div data-slot="card-header" class="@container/card-header grid auto-rows-min grid-rows-[auto_auto] items-start gap-2 px-6 has-data-[slot=card-action]:grid-cols-[1fr_auto] [.border-b]:pb-6 pb-3"><div class="flex items-start justify-between gap-4"><div class="flex-1 space-y-2"><h3 class="font-serif text-xl font-medium leading-tight text-foreground group-hover:text-primary transition-colors"><a target="_blank" rel="noopener noreferrer" class="flex items-center gap-2 hover:underline decoration-primary/30 underline-offset-4" href="https://hparch.gatech.edu/papers/shoghi_src_esweek.pdf">SLAM Performance on Embedded Robots<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-arrow-up-right h-4 w-4 opacity-50" aria-hidden="true"><path d="M7 7h10v10"></path><path d="M7 17 17 7"></path></svg></a></h3><div class="flex flex-wrap items-center gap-2"><span data-slot="badge" class="inline-flex items-center justify-center rounded-full border px-2 py-0.5 text-xs w-fit whitespace-nowrap shrink-0 [&amp;&gt;svg]:size-3 gap-1 [&amp;&gt;svg]:pointer-events-none focus-visible:border-ring focus-visible:ring-ring/50 focus-visible:ring-[3px] aria-invalid:ring-destructive/20 dark:aria-invalid:ring-destructive/40 aria-invalid:border-destructive transition-[color,box-shadow] overflow-hidden border-transparent text-secondary-foreground [a&amp;]:hover:bg-secondary/90 bg-secondary/50 font-normal">Student Research Competition at Embedded System Week (SRC ESWEEK)</span><span data-slot="badge" class="inline-flex items-center justify-center rounded-full border px-2 py-0.5 text-xs w-fit whitespace-nowrap shrink-0 [&amp;&gt;svg]:size-3 gap-1 [&amp;&gt;svg]:pointer-events-none focus-visible:border-ring focus-visible:ring-ring/50 focus-visible:ring-[3px] aria-invalid:ring-destructive/20 dark:aria-invalid:ring-destructive/40 aria-invalid:border-destructive transition-[color,box-shadow] overflow-hidden [a&amp;]:hover:bg-accent [a&amp;]:hover:text-accent-foreground font-normal text-muted-foreground">2019</span></div></div></div></div><div data-slot="card-content" class="px-6 pt-0 relative z-10 flex-1 flex flex-col justify-between"><div><p class="text-sm text-muted-foreground font-medium"><b>Nima Shoghi</b>, Ramyad Hadidi, Hyesoon Kim</p><p class="mt-2 text-sm leading-relaxed text-foreground/80">Demonstrates the feasibility of running ORB-SLAM2 in real-time on the Raspberry Pi 3B+ for embedded robots through optimizations that achieved a 5x speedup with minor impact on accuracy.</p></div><div class="mt-4 flex"><a target="_blank" rel="noopener noreferrer" class="inline-flex items-center gap-1.5 text-xs font-medium text-primary hover:text-primary/80 transition-colors" href="https://hparch.gatech.edu/papers/shoghi_src_esweek.pdf"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-file-text h-3.5 w-3.5" aria-hidden="true"><path d="M6 22a2 2 0 0 1-2-2V4a2 2 0 0 1 2-2h8a2.4 2.4 0 0 1 1.704.706l3.588 3.588A2.4 2.4 0 0 1 20 8v12a2 2 0 0 1-2 2z"></path><path d="M14 2v5a1 1 0 0 0 1 1h5"></path><path d="M10 9H8"></path><path d="M16 13H8"></path><path d="M16 17H8"></path></svg>Read Paper</a></div></div></div></div></div></div></div></div></div></section></div><!--$--><!--/$--></main><footer class="border-t border-border/40 bg-background"><div class="mx-auto max-w-5xl px-4 py-8 sm:px-6 lg:px-8"><div class="flex flex-col items-center justify-between gap-4 sm:flex-row"><p class="text-sm text-muted-foreground"> <!-- -->2025<!-- --> Nima Shoghi. All rights reserved.</p><div class="flex items-center gap-4"><a class="text-muted-foreground transition-colors hover:text-foreground" target="_blank" rel="noopener noreferrer" aria-label="GitHub" href="https://github.com/nimashoghi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-github h-5 w-5" aria-hidden="true"><path d="M15 22v-4a4.8 4.8 0 0 0-1-3.5c3 0 6-2 6-5.5.08-1.25-.27-2.48-1-3.5.28-1.15.28-2.35 0-3.5 0 0-1 0-3 1.5-2.64-.5-5.36-.5-8 0C6 2 5 2 5 2c-.3 1.15-.3 2.35 0 3.5A5.403 5.403 0 0 0 4 9c0 3.5 3 5.5 6 5.5-.39.49-.68 1.05-.85 1.65-.17.6-.22 1.23-.15 1.85v4"></path><path d="M9 18c-4.51 2-5-2-7-2"></path></svg></a><a class="text-muted-foreground transition-colors hover:text-foreground" target="_blank" rel="noopener noreferrer" aria-label="LinkedIn" href="https://linkedin.com/in/nimashoghi"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-linkedin h-5 w-5" aria-hidden="true"><path d="M16 8a6 6 0 0 1 6 6v7h-4v-7a2 2 0 0 0-2-2 2 2 0 0 0-2 2v7h-4v-7a6 6 0 0 1 6-6z"></path><rect width="4" height="12" x="2" y="9"></rect><circle cx="4" cy="4" r="2"></circle></svg></a><a class="text-muted-foreground transition-colors hover:text-foreground" target="_blank" rel="noopener noreferrer" aria-label="Twitter" href="https://twitter.com/nimawrites"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-twitter h-5 w-5" aria-hidden="true"><path d="M22 4s-.7 2.1-2 3.4c1.6 10-9.4 17.3-18 11.6 2.2.1 4.4-.6 6-2C3 15.5.5 9.6 3 5c2.2 2.6 5.6 4.1 9 4-.9-4.2 4-6.6 7-3.8 1.1 0 3-1.2 3-1.2z"></path></svg></a><a class="text-muted-foreground transition-colors hover:text-foreground" target="_blank" rel="noopener noreferrer" aria-label="Email" href="mailto:nimash@gatech.edu"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-mail h-5 w-5" aria-hidden="true"><path d="m22 7-8.991 5.727a2 2 0 0 1-2.009 0L2 7"></path><rect x="2" y="4" width="20" height="16" rx="2"></rect></svg></a></div></div></div></footer></div><script src="/_next/static/chunks/28072458dcfc9429.js" id="_R_" async=""></script><script>(self.__next_f=self.__next_f||[]).push([0])</script><script>self.__next_f.push([1,"1:\"$Sreact.fragment\"\n2:I[27423,[\"/_next/static/chunks/8a0e79cbb1274723.js\",\"/_next/static/chunks/febf79354ea0b539.js\",\"/_next/static/chunks/a78e08c828fdf356.js\"],\"ThemeProvider\"]\n3:I[45872,[\"/_next/static/chunks/8a0e79cbb1274723.js\",\"/_next/static/chunks/febf79354ea0b539.js\",\"/_next/static/chunks/a78e08c828fdf356.js\"],\"Header\"]\n4:I[93099,[\"/_next/static/chunks/04ffb94433a93116.js\",\"/_next/static/chunks/f9e056060c220c2e.js\"],\"default\"]\n5:I[65125,[\"/_next/static/chunks/04ffb94433a93116.js\",\"/_next/static/chunks/f9e056060c220c2e.js\"],\"default\"]\n6:I[51079,[\"/_next/static/chunks/8a0e79cbb1274723.js\",\"/_next/static/chunks/febf79354ea0b539.js\",\"/_next/static/chunks/a78e08c828fdf356.js\"],\"\"]\nb:I[84744,[\"/_next/static/chunks/04ffb94433a93116.js\",\"/_next/static/chunks/f9e056060c220c2e.js\"],\"default\"]\n:HL[\"/_next/static/chunks/edc9b9eff40ea36b.css\",\"style\"]\n:HL[\"/_next/static/media/2a65768255d6b625-s.p.d19752fb.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\n:HL[\"/_next/static/media/83afe278b6a6bb3c-s.p.3a6ba036.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\n"])</script><script>self.__next_f.push([1,"0:{\"P\":null,\"b\":\"rtrE89DNrUWMal_sRfms0\",\"c\":[\"\",\"publications\"],\"q\":\"\",\"i\":false,\"f\":[[[\"\",{\"children\":[\"publications\",{\"children\":[\"__PAGE__\",{}]}]},\"$undefined\",\"$undefined\",true],[[\"$\",\"$1\",\"c\",{\"children\":[[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/chunks/edc9b9eff40ea36b.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\",\"nonce\":\"$undefined\"}],[\"$\",\"script\",\"script-0\",{\"src\":\"/_next/static/chunks/8a0e79cbb1274723.js\",\"async\":true,\"nonce\":\"$undefined\"}],[\"$\",\"script\",\"script-1\",{\"src\":\"/_next/static/chunks/febf79354ea0b539.js\",\"async\":true,\"nonce\":\"$undefined\"}],[\"$\",\"script\",\"script-2\",{\"src\":\"/_next/static/chunks/a78e08c828fdf356.js\",\"async\":true,\"nonce\":\"$undefined\"}]],[\"$\",\"html\",null,{\"lang\":\"en\",\"className\":\"scroll-smooth\",\"suppressHydrationWarning\":true,\"children\":[\"$\",\"body\",null,{\"className\":\"inter_786c1081-module__J60SBq__variable playfair_display_bd0c5d65-module___OUtNG__variable font-sans antialiased bg-background text-foreground selection:bg-primary/10 selection:text-primary\",\"children\":[\"$\",\"$L2\",null,{\"attribute\":\"class\",\"defaultTheme\":\"system\",\"enableSystem\":true,\"disableTransitionOnChange\":true,\"children\":[\"$\",\"div\",null,{\"className\":\"relative flex min-h-screen flex-col\",\"children\":[[\"$\",\"div\",null,{\"className\":\"fixed inset-0 -z-10 h-full w-full bg-background overflow-hidden\",\"children\":[[\"$\",\"div\",null,{\"className\":\"absolute inset-0 bg-[linear-gradient(to_right,#8080800a_1px,transparent_1px),linear-gradient(to_bottom,#8080800a_1px,transparent_1px)] bg-size-[24px_24px]\"}],[\"$\",\"div\",null,{\"className\":\"absolute left-0 right-0 top-[-10%] -z-10 m-auto h-125 w-125 rounded-full bg-primary/20 opacity-30 blur-[100px]\"}],[\"$\",\"div\",null,{\"className\":\"absolute bottom-[-10%] right-[-10%] -z-10 h-100 w-100 rounded-full bg-primary/10 opacity-20 blur-[100px]\"}]]}],[\"$\",\"$L3\",null,{}],[\"$\",\"main\",null,{\"className\":\"flex-1\",\"children\":[\"$\",\"$L4\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L5\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":[[\"$\",\"div\",null,{\"className\":\"mx-auto flex min-h-[60vh] max-w-5xl flex-col items-center justify-center px-4 text-center sm:px-6 lg:px-8\",\"children\":[[\"$\",\"h1\",null,{\"className\":\"text-9xl font-bold text-muted-foreground/20\",\"children\":\"404\"}],[\"$\",\"h2\",null,{\"className\":\"mt-4 text-2xl font-semibold text-foreground\",\"children\":\"Page Not Found\"}],[\"$\",\"p\",null,{\"className\":\"mt-2 text-muted-foreground\",\"children\":\"The page you're looking for doesn't exist or has been moved.\"}],[\"$\",\"$L6\",null,{\"href\":\"/\",\"children\":[[\"$\",\"svg\",null,{\"ref\":\"$undefined\",\"xmlns\":\"http://www.w3.org/2000/svg\",\"width\":24,\"height\":24,\"viewBox\":\"0 0 24 24\",\"fill\":\"none\",\"stroke\":\"currentColor\",\"strokeWidth\":2,\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"className\":\"lucide lucide-house mr-2 h-4 w-4\",\"aria-hidden\":\"true\",\"children\":[[\"$\",\"path\",\"5wwlr5\",{\"d\":\"M15 21v-8a1 1 0 0 0-1-1h-4a1 1 0 0 0-1 1v8\"}],[\"$\",\"path\",\"r6nss1\",{\"d\":\"M3 10a2 2 0 0 1 .709-1.528l7-6a2 2 0 0 1 2.582 0l7 6A2 2 0 0 1 21 10v9a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2z\"}],\"$undefined\"]}],\"Back to Home\"],\"data-slot\":\"button\",\"data-variant\":\"default\",\"data-size\":\"default\",\"className\":\"inline-flex items-center justify-center gap-2 whitespace-nowrap rounded-md text-sm font-medium transition-all disabled:pointer-events-none disabled:opacity-50 [\u0026_svg]:pointer-events-none [\u0026_svg:not([class*='size-'])]:size-4 shrink-0 [\u0026_svg]:shrink-0 outline-none focus-visible:border-ring focus-visible:ring-ring/50 focus-visible:ring-[3px] aria-invalid:ring-destructive/20 dark:aria-invalid:ring-destructive/40 aria-invalid:border-destructive bg-primary text-primary-foreground hover:bg-primary/90 h-9 px-4 py-2 has-[\u003esvg]:px-3 mt-8\",\"ref\":null}]]}],[]],\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]}],[\"$\",\"footer\",null,{\"className\":\"border-t border-border/40 bg-background\",\"children\":[\"$\",\"div\",null,{\"className\":\"mx-auto max-w-5xl px-4 py-8 sm:px-6 lg:px-8\",\"children\":[\"$\",\"div\",null,{\"className\":\"flex flex-col items-center justify-between gap-4 sm:flex-row\",\"children\":[[\"$\",\"p\",null,{\"className\":\"text-sm text-muted-foreground\",\"children\":[\" \",2025,\" Nima Shoghi. All rights reserved.\"]}],\"$L7\"]}]}]}]]}]}]}]}]]}],{\"children\":[\"$L8\",{\"children\":[\"$L9\",{},null,false,false]},null,false,false]},null,false,false],\"$La\",false]],\"m\":\"$undefined\",\"G\":[\"$b\",[]],\"S\":true}\n"])</script><script>self.__next_f.push([1,"c:I[88206,[\"/_next/static/chunks/04ffb94433a93116.js\",\"/_next/static/chunks/f9e056060c220c2e.js\"],\"ClientPageRoot\"]\nd:I[46093,[\"/_next/static/chunks/8a0e79cbb1274723.js\",\"/_next/static/chunks/febf79354ea0b539.js\",\"/_next/static/chunks/a78e08c828fdf356.js\",\"/_next/static/chunks/e9c835b7a74e008c.js\",\"/_next/static/chunks/31a6224758fe9544.js\"],\"default\"]\n10:I[60571,[\"/_next/static/chunks/04ffb94433a93116.js\",\"/_next/static/chunks/f9e056060c220c2e.js\"],\"OutletBoundary\"]\n11:\"$Sreact.suspense\"\n13:I[60571,[\"/_next/static/chunks/04ffb94433a93116.js\",\"/_next/static/chunks/f9e056060c220c2e.js\"],\"ViewportBoundary\"]\n15:I[60571,[\"/_next/static/chunks/04ffb94433a93116.js\",\"/_next/static/chunks/f9e056060c220c2e.js\"],\"MetadataBoundary\"]\n"])</script><script>self.__next_f.push([1,"7:[\"$\",\"div\",null,{\"className\":\"flex items-center gap-4\",\"children\":[[\"$\",\"$L6\",\"GitHub\",{\"href\":\"https://github.com/nimashoghi\",\"className\":\"text-muted-foreground transition-colors hover:text-foreground\",\"target\":\"_blank\",\"rel\":\"noopener noreferrer\",\"aria-label\":\"GitHub\",\"children\":[\"$\",\"svg\",null,{\"ref\":\"$undefined\",\"xmlns\":\"http://www.w3.org/2000/svg\",\"width\":24,\"height\":24,\"viewBox\":\"0 0 24 24\",\"fill\":\"none\",\"stroke\":\"currentColor\",\"strokeWidth\":2,\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"className\":\"lucide lucide-github h-5 w-5\",\"aria-hidden\":\"true\",\"children\":[[\"$\",\"path\",\"tonef\",{\"d\":\"M15 22v-4a4.8 4.8 0 0 0-1-3.5c3 0 6-2 6-5.5.08-1.25-.27-2.48-1-3.5.28-1.15.28-2.35 0-3.5 0 0-1 0-3 1.5-2.64-.5-5.36-.5-8 0C6 2 5 2 5 2c-.3 1.15-.3 2.35 0 3.5A5.403 5.403 0 0 0 4 9c0 3.5 3 5.5 6 5.5-.39.49-.68 1.05-.85 1.65-.17.6-.22 1.23-.15 1.85v4\"}],[\"$\",\"path\",\"9comsn\",{\"d\":\"M9 18c-4.51 2-5-2-7-2\"}],\"$undefined\"]}]}],[\"$\",\"$L6\",\"LinkedIn\",{\"href\":\"https://linkedin.com/in/nimashoghi\",\"className\":\"text-muted-foreground transition-colors hover:text-foreground\",\"target\":\"_blank\",\"rel\":\"noopener noreferrer\",\"aria-label\":\"LinkedIn\",\"children\":[\"$\",\"svg\",null,{\"ref\":\"$undefined\",\"xmlns\":\"http://www.w3.org/2000/svg\",\"width\":24,\"height\":24,\"viewBox\":\"0 0 24 24\",\"fill\":\"none\",\"stroke\":\"currentColor\",\"strokeWidth\":2,\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"className\":\"lucide lucide-linkedin h-5 w-5\",\"aria-hidden\":\"true\",\"children\":[[\"$\",\"path\",\"c2jq9f\",{\"d\":\"M16 8a6 6 0 0 1 6 6v7h-4v-7a2 2 0 0 0-2-2 2 2 0 0 0-2 2v7h-4v-7a6 6 0 0 1 6-6z\"}],[\"$\",\"rect\",\"mk3on5\",{\"width\":\"4\",\"height\":\"12\",\"x\":\"2\",\"y\":\"9\"}],[\"$\",\"circle\",\"bt5ra8\",{\"cx\":\"4\",\"cy\":\"4\",\"r\":\"2\"}],\"$undefined\"]}]}],[\"$\",\"$L6\",\"Twitter\",{\"href\":\"https://twitter.com/nimawrites\",\"className\":\"text-muted-foreground transition-colors hover:text-foreground\",\"target\":\"_blank\",\"rel\":\"noopener noreferrer\",\"aria-label\":\"Twitter\",\"children\":[\"$\",\"svg\",null,{\"ref\":\"$undefined\",\"xmlns\":\"http://www.w3.org/2000/svg\",\"width\":24,\"height\":24,\"viewBox\":\"0 0 24 24\",\"fill\":\"none\",\"stroke\":\"currentColor\",\"strokeWidth\":2,\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"className\":\"lucide lucide-twitter h-5 w-5\",\"aria-hidden\":\"true\",\"children\":[[\"$\",\"path\",\"pff0z6\",{\"d\":\"M22 4s-.7 2.1-2 3.4c1.6 10-9.4 17.3-18 11.6 2.2.1 4.4-.6 6-2C3 15.5.5 9.6 3 5c2.2 2.6 5.6 4.1 9 4-.9-4.2 4-6.6 7-3.8 1.1 0 3-1.2 3-1.2z\"}],\"$undefined\"]}]}],[\"$\",\"$L6\",\"Email\",{\"href\":\"mailto:nimash@gatech.edu\",\"className\":\"text-muted-foreground transition-colors hover:text-foreground\",\"target\":\"_blank\",\"rel\":\"noopener noreferrer\",\"aria-label\":\"Email\",\"children\":[\"$\",\"svg\",null,{\"ref\":\"$undefined\",\"xmlns\":\"http://www.w3.org/2000/svg\",\"width\":24,\"height\":24,\"viewBox\":\"0 0 24 24\",\"fill\":\"none\",\"stroke\":\"currentColor\",\"strokeWidth\":2,\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"className\":\"lucide lucide-mail h-5 w-5\",\"aria-hidden\":\"true\",\"children\":[[\"$\",\"path\",\"132q7q\",{\"d\":\"m22 7-8.991 5.727a2 2 0 0 1-2.009 0L2 7\"}],[\"$\",\"rect\",\"izxlao\",{\"x\":\"2\",\"y\":\"4\",\"width\":\"20\",\"height\":\"16\",\"rx\":\"2\"}],\"$undefined\"]}]}]]}]\n"])</script><script>self.__next_f.push([1,"8:[\"$\",\"$1\",\"c\",{\"children\":[null,[\"$\",\"$L4\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L5\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]]}]\n9:[\"$\",\"$1\",\"c\",{\"children\":[[\"$\",\"$Lc\",null,{\"Component\":\"$d\",\"serverProvidedParams\":{\"searchParams\":{},\"params\":{},\"promises\":[\"$@e\",\"$@f\"]}}],[[\"$\",\"script\",\"script-0\",{\"src\":\"/_next/static/chunks/e9c835b7a74e008c.js\",\"async\":true,\"nonce\":\"$undefined\"}],[\"$\",\"script\",\"script-1\",{\"src\":\"/_next/static/chunks/31a6224758fe9544.js\",\"async\":true,\"nonce\":\"$undefined\"}]],[\"$\",\"$L10\",null,{\"children\":[\"$\",\"$11\",null,{\"name\":\"Next.MetadataOutlet\",\"children\":\"$@12\"}]}]]}]\na:[\"$\",\"$1\",\"h\",{\"children\":[null,[\"$\",\"$L13\",null,{\"children\":\"$@14\"}],[\"$\",\"div\",null,{\"hidden\":true,\"children\":[\"$\",\"$L15\",null,{\"children\":[\"$\",\"$11\",null,{\"name\":\"Next.Metadata\",\"children\":\"$@16\"}]}]}],[\"$\",\"meta\",null,{\"name\":\"next-size-adjust\",\"content\":\"\"}]]}]\n"])</script><script>self.__next_f.push([1,"e:{}\nf:\"$9:props:children:0:props:serverProvidedParams:params\"\n"])</script><script>self.__next_f.push([1,"14:[[\"$\",\"meta\",\"0\",{\"charSet\":\"utf-8\"}],[\"$\",\"meta\",\"1\",{\"name\":\"viewport\",\"content\":\"width=device-width, initial-scale=1\"}]]\n"])</script><script>self.__next_f.push([1,"17:I[75022,[\"/_next/static/chunks/04ffb94433a93116.js\",\"/_next/static/chunks/f9e056060c220c2e.js\"],\"IconMark\"]\n"])</script><script>self.__next_f.push([1,"16:[[\"$\",\"title\",\"0\",{\"children\":\"Publications | Nima Shoghi\"}],[\"$\",\"meta\",\"1\",{\"name\":\"description\",\"content\":\"Research publications by Nima Shoghi in machine learning, chemistry, and materials science.\"}],[\"$\",\"meta\",\"2\",{\"name\":\"author\",\"content\":\"Nima Shoghi\"}],[\"$\",\"link\",\"3\",{\"rel\":\"manifest\",\"href\":\"/manifest.json\",\"crossOrigin\":\"$undefined\"}],[\"$\",\"meta\",\"4\",{\"name\":\"keywords\",\"content\":\"Machine Learning,PhD,Georgia Tech,Deep Learning,AI for Science,Chemistry,Materials Science\"}],[\"$\",\"meta\",\"5\",{\"name\":\"creator\",\"content\":\"Nima Shoghi\"}],[\"$\",\"meta\",\"6\",{\"name\":\"robots\",\"content\":\"index, follow\"}],[\"$\",\"meta\",\"7\",{\"property\":\"og:title\",\"content\":\"Nima Shoghi | ML PhD Student\"}],[\"$\",\"meta\",\"8\",{\"property\":\"og:description\",\"content\":\"PhD student in Machine Learning at Georgia Tech, focusing on Deep Learning for Scientific Applications.\"}],[\"$\",\"meta\",\"9\",{\"property\":\"og:url\",\"content\":\"https://nima.sh\"}],[\"$\",\"meta\",\"10\",{\"property\":\"og:site_name\",\"content\":\"Nima Shoghi\"}],[\"$\",\"meta\",\"11\",{\"property\":\"og:locale\",\"content\":\"en_US\"}],[\"$\",\"meta\",\"12\",{\"property\":\"og:type\",\"content\":\"website\"}],[\"$\",\"meta\",\"13\",{\"name\":\"twitter:card\",\"content\":\"summary_large_image\"}],[\"$\",\"meta\",\"14\",{\"name\":\"twitter:creator\",\"content\":\"@nimawrites\"}],[\"$\",\"meta\",\"15\",{\"name\":\"twitter:title\",\"content\":\"Nima Shoghi | ML PhD Student\"}],[\"$\",\"meta\",\"16\",{\"name\":\"twitter:description\",\"content\":\"PhD student in Machine Learning at Georgia Tech, focusing on Deep Learning for Scientific Applications.\"}],[\"$\",\"link\",\"17\",{\"rel\":\"icon\",\"href\":\"/favicon.ico\",\"sizes\":\"any\"}],[\"$\",\"link\",\"18\",{\"rel\":\"icon\",\"href\":\"/favicon.svg\",\"type\":\"image/svg+xml\",\"media\":\"(prefers-color-scheme: light)\"}],[\"$\",\"link\",\"19\",{\"rel\":\"icon\",\"href\":\"/favicon-dark.svg\",\"type\":\"image/svg+xml\",\"media\":\"(prefers-color-scheme: dark)\"}],[\"$\",\"link\",\"20\",{\"rel\":\"icon\",\"href\":\"/favicon-32.png\",\"type\":\"image/png\",\"sizes\":\"32x32\"}],[\"$\",\"link\",\"21\",{\"rel\":\"icon\",\"href\":\"/favicon-16.png\",\"type\":\"image/png\",\"sizes\":\"16x16\"}],[\"$\",\"link\",\"22\",{\"rel\":\"icon\",\"href\":\"/favicon-512.png\",\"type\":\"image/png\",\"sizes\":\"512x512\",\"media\":\"(prefers-color-scheme: light)\"}],[\"$\",\"link\",\"23\",{\"rel\":\"icon\",\"href\":\"/favicon-dark-512.png\",\"type\":\"image/png\",\"sizes\":\"512x512\",\"media\":\"(prefers-color-scheme: dark)\"}],[\"$\",\"link\",\"24\",{\"rel\":\"apple-touch-icon\",\"href\":\"/favicon-192.png\",\"sizes\":\"180x180\",\"type\":\"image/png\"}],[\"$\",\"$L17\",\"25\",{}]]\n"])</script><script>self.__next_f.push([1,"12:null\n"])</script></body></html>