1:"$Sreact.fragment"
2:I[27423,["/_next/static/chunks/8a0e79cbb1274723.js","/_next/static/chunks/febf79354ea0b539.js","/_next/static/chunks/a78e08c828fdf356.js"],"ThemeProvider"]
3:I[45872,["/_next/static/chunks/8a0e79cbb1274723.js","/_next/static/chunks/febf79354ea0b539.js","/_next/static/chunks/a78e08c828fdf356.js"],"Header"]
4:I[93099,["/_next/static/chunks/04ffb94433a93116.js","/_next/static/chunks/f9e056060c220c2e.js"],"default"]
5:I[65125,["/_next/static/chunks/04ffb94433a93116.js","/_next/static/chunks/f9e056060c220c2e.js"],"default"]
6:I[51079,["/_next/static/chunks/8a0e79cbb1274723.js","/_next/static/chunks/febf79354ea0b539.js","/_next/static/chunks/a78e08c828fdf356.js"],""]
b:I[84744,["/_next/static/chunks/04ffb94433a93116.js","/_next/static/chunks/f9e056060c220c2e.js"],"default"]
:HL["/_next/static/chunks/edc9b9eff40ea36b.css","style"]
:HL["/_next/static/media/2a65768255d6b625-s.p.d19752fb.woff2","font",{"crossOrigin":"","type":"font/woff2"}]
:HL["/_next/static/media/83afe278b6a6bb3c-s.p.3a6ba036.woff2","font",{"crossOrigin":"","type":"font/woff2"}]
0:{"P":null,"b":"rtrE89DNrUWMal_sRfms0","c":["","experience"],"q":"","i":false,"f":[[["",{"children":["experience",{"children":["__PAGE__",{}]}]},"$undefined","$undefined",true],[["$","$1","c",{"children":[[["$","link","0",{"rel":"stylesheet","href":"/_next/static/chunks/edc9b9eff40ea36b.css","precedence":"next","crossOrigin":"$undefined","nonce":"$undefined"}],["$","script","script-0",{"src":"/_next/static/chunks/8a0e79cbb1274723.js","async":true,"nonce":"$undefined"}],["$","script","script-1",{"src":"/_next/static/chunks/febf79354ea0b539.js","async":true,"nonce":"$undefined"}],["$","script","script-2",{"src":"/_next/static/chunks/a78e08c828fdf356.js","async":true,"nonce":"$undefined"}]],["$","html",null,{"lang":"en","className":"scroll-smooth","suppressHydrationWarning":true,"children":["$","body",null,{"className":"inter_786c1081-module__J60SBq__variable playfair_display_bd0c5d65-module___OUtNG__variable font-sans antialiased bg-background text-foreground selection:bg-primary/10 selection:text-primary","children":["$","$L2",null,{"attribute":"class","defaultTheme":"system","enableSystem":true,"disableTransitionOnChange":true,"children":["$","div",null,{"className":"relative flex min-h-screen flex-col","children":[["$","div",null,{"className":"fixed inset-0 -z-10 h-full w-full bg-background overflow-hidden","children":[["$","div",null,{"className":"absolute inset-0 bg-[linear-gradient(to_right,#8080800a_1px,transparent_1px),linear-gradient(to_bottom,#8080800a_1px,transparent_1px)] bg-size-[24px_24px]"}],["$","div",null,{"className":"absolute left-0 right-0 top-[-10%] -z-10 m-auto h-125 w-125 rounded-full bg-primary/20 opacity-30 blur-[100px]"}],["$","div",null,{"className":"absolute bottom-[-10%] right-[-10%] -z-10 h-100 w-100 rounded-full bg-primary/10 opacity-20 blur-[100px]"}]]}],["$","$L3",null,{}],["$","main",null,{"className":"flex-1","children":["$","$L4",null,{"parallelRouterKey":"children","error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L5",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":[["$","div",null,{"className":"mx-auto flex min-h-[60vh] max-w-5xl flex-col items-center justify-center px-4 text-center sm:px-6 lg:px-8","children":[["$","h1",null,{"className":"text-9xl font-bold text-muted-foreground/20","children":"404"}],["$","h2",null,{"className":"mt-4 text-2xl font-semibold text-foreground","children":"Page Not Found"}],["$","p",null,{"className":"mt-2 text-muted-foreground","children":"The page you're looking for doesn't exist or has been moved."}],["$","$L6",null,{"href":"/","children":[["$","svg",null,{"ref":"$undefined","xmlns":"http://www.w3.org/2000/svg","width":24,"height":24,"viewBox":"0 0 24 24","fill":"none","stroke":"currentColor","strokeWidth":2,"strokeLinecap":"round","strokeLinejoin":"round","className":"lucide lucide-house mr-2 h-4 w-4","aria-hidden":"true","children":[["$","path","5wwlr5",{"d":"M15 21v-8a1 1 0 0 0-1-1h-4a1 1 0 0 0-1 1v8"}],["$","path","r6nss1",{"d":"M3 10a2 2 0 0 1 .709-1.528l7-6a2 2 0 0 1 2.582 0l7 6A2 2 0 0 1 21 10v9a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2z"}],"$undefined"]}],"Back to Home"],"data-slot":"button","data-variant":"default","data-size":"default","className":"inline-flex items-center justify-center gap-2 whitespace-nowrap rounded-md text-sm font-medium transition-all disabled:pointer-events-none disabled:opacity-50 [&_svg]:pointer-events-none [&_svg:not([class*='size-'])]:size-4 shrink-0 [&_svg]:shrink-0 outline-none focus-visible:border-ring focus-visible:ring-ring/50 focus-visible:ring-[3px] aria-invalid:ring-destructive/20 dark:aria-invalid:ring-destructive/40 aria-invalid:border-destructive bg-primary text-primary-foreground hover:bg-primary/90 h-9 px-4 py-2 has-[>svg]:px-3 mt-8","ref":null}]]}],[]],"forbidden":"$undefined","unauthorized":"$undefined"}]}],["$","footer",null,{"className":"border-t border-border/40 bg-background","children":["$","div",null,{"className":"mx-auto max-w-5xl px-4 py-8 sm:px-6 lg:px-8","children":["$","div",null,{"className":"flex flex-col items-center justify-between gap-4 sm:flex-row","children":[["$","p",null,{"className":"text-sm text-muted-foreground","children":["© ",2025," Nima Shoghi. All rights reserved."]}],"$L7"]}]}]}]]}]}]}]}]]}],{"children":["$L8",{"children":["$L9",{},null,false,false]},null,false,false]},null,false,false],"$La",false]],"m":"$undefined","G":["$b",[]],"S":true}
c:I[82027,["/_next/static/chunks/8a0e79cbb1274723.js","/_next/static/chunks/febf79354ea0b539.js","/_next/static/chunks/a78e08c828fdf356.js","/_next/static/chunks/602835b498330a9d.js","/_next/static/chunks/99bc80f84e40b175.js"],"ExperienceCard"]
d:I[72436,["/_next/static/chunks/8a0e79cbb1274723.js","/_next/static/chunks/febf79354ea0b539.js","/_next/static/chunks/a78e08c828fdf356.js","/_next/static/chunks/602835b498330a9d.js","/_next/static/chunks/99bc80f84e40b175.js"],"Separator"]
19:I[60571,["/_next/static/chunks/04ffb94433a93116.js","/_next/static/chunks/f9e056060c220c2e.js"],"ViewportBoundary"]
1b:I[60571,["/_next/static/chunks/04ffb94433a93116.js","/_next/static/chunks/f9e056060c220c2e.js"],"MetadataBoundary"]
1c:"$Sreact.suspense"
7:["$","div",null,{"className":"flex items-center gap-4","children":[["$","$L6","GitHub",{"href":"https://github.com/nimashoghi","className":"text-muted-foreground transition-colors hover:text-foreground","target":"_blank","rel":"noopener noreferrer","aria-label":"GitHub","children":["$","svg",null,{"ref":"$undefined","xmlns":"http://www.w3.org/2000/svg","width":24,"height":24,"viewBox":"0 0 24 24","fill":"none","stroke":"currentColor","strokeWidth":2,"strokeLinecap":"round","strokeLinejoin":"round","className":"lucide lucide-github h-5 w-5","aria-hidden":"true","children":[["$","path","tonef",{"d":"M15 22v-4a4.8 4.8 0 0 0-1-3.5c3 0 6-2 6-5.5.08-1.25-.27-2.48-1-3.5.28-1.15.28-2.35 0-3.5 0 0-1 0-3 1.5-2.64-.5-5.36-.5-8 0C6 2 5 2 5 2c-.3 1.15-.3 2.35 0 3.5A5.403 5.403 0 0 0 4 9c0 3.5 3 5.5 6 5.5-.39.49-.68 1.05-.85 1.65-.17.6-.22 1.23-.15 1.85v4"}],["$","path","9comsn",{"d":"M9 18c-4.51 2-5-2-7-2"}],"$undefined"]}]}],["$","$L6","LinkedIn",{"href":"https://linkedin.com/in/nimashoghi","className":"text-muted-foreground transition-colors hover:text-foreground","target":"_blank","rel":"noopener noreferrer","aria-label":"LinkedIn","children":["$","svg",null,{"ref":"$undefined","xmlns":"http://www.w3.org/2000/svg","width":24,"height":24,"viewBox":"0 0 24 24","fill":"none","stroke":"currentColor","strokeWidth":2,"strokeLinecap":"round","strokeLinejoin":"round","className":"lucide lucide-linkedin h-5 w-5","aria-hidden":"true","children":[["$","path","c2jq9f",{"d":"M16 8a6 6 0 0 1 6 6v7h-4v-7a2 2 0 0 0-2-2 2 2 0 0 0-2 2v7h-4v-7a6 6 0 0 1 6-6z"}],["$","rect","mk3on5",{"width":"4","height":"12","x":"2","y":"9"}],["$","circle","bt5ra8",{"cx":"4","cy":"4","r":"2"}],"$undefined"]}]}],["$","$L6","Twitter",{"href":"https://twitter.com/nimawrites","className":"text-muted-foreground transition-colors hover:text-foreground","target":"_blank","rel":"noopener noreferrer","aria-label":"Twitter","children":["$","svg",null,{"ref":"$undefined","xmlns":"http://www.w3.org/2000/svg","width":24,"height":24,"viewBox":"0 0 24 24","fill":"none","stroke":"currentColor","strokeWidth":2,"strokeLinecap":"round","strokeLinejoin":"round","className":"lucide lucide-twitter h-5 w-5","aria-hidden":"true","children":[["$","path","pff0z6",{"d":"M22 4s-.7 2.1-2 3.4c1.6 10-9.4 17.3-18 11.6 2.2.1 4.4-.6 6-2C3 15.5.5 9.6 3 5c2.2 2.6 5.6 4.1 9 4-.9-4.2 4-6.6 7-3.8 1.1 0 3-1.2 3-1.2z"}],"$undefined"]}]}],["$","$L6","Email",{"href":"mailto:nimash@gatech.edu","className":"text-muted-foreground transition-colors hover:text-foreground","target":"_blank","rel":"noopener noreferrer","aria-label":"Email","children":["$","svg",null,{"ref":"$undefined","xmlns":"http://www.w3.org/2000/svg","width":24,"height":24,"viewBox":"0 0 24 24","fill":"none","stroke":"currentColor","strokeWidth":2,"strokeLinecap":"round","strokeLinejoin":"round","className":"lucide lucide-mail h-5 w-5","aria-hidden":"true","children":[["$","path","132q7q",{"d":"m22 7-8.991 5.727a2 2 0 0 1-2.009 0L2 7"}],["$","rect","izxlao",{"x":"2","y":"4","width":"20","height":"16","rx":"2"}],"$undefined"]}]}]]}]
8:["$","$1","c",{"children":[null,["$","$L4",null,{"parallelRouterKey":"children","error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L5",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","forbidden":"$undefined","unauthorized":"$undefined"}]]}]
9:["$","$1","c",{"children":[["$","div",null,{"className":"mx-auto max-w-5xl px-4 py-12 sm:px-6 lg:px-8","children":[["$","section",null,{"id":"education","className":"py-12","children":[["$","div",null,{"className":"mb-8","children":[["$","h2",null,{"className":"font-serif text-3xl font-bold tracking-tight text-foreground sm:text-4xl","children":"Education"}],["$","p",null,{"className":"mt-2 text-lg text-muted-foreground","children":"Academic background and degrees"}]]}],["$","div",null,{"className":"grid gap-8","children":[["$","$Lc","Georgia Institute of Technology-0",{"experience":{"title":"PhD in Machine Learning, 4.0 GPA","shortTitle":"PhD in Machine Learning, 4.0 GPA","organization":"Georgia Institute of Technology","organizationUrl":"https://www.gatech.edu/","startDate":"2024","endDate":"2028 (expected)","highlight":true,"description":["Advisors: Dr. Pan Li and Dr. Victor Fung","Research Focus: Deep Learning for Scientific Applications","NSF Graduate Research Fellowship Honorable Mention (2024)","CSGF Fellowship Alternate List (2025)"],"highlightDescription":["Advisors: Dr. Pan Li and Dr. Victor Fung","Research Interest: Developing ML techniques to solve complex problems in the scientific and engineering domains."],"advisorLinks":[{"name":"Dr. Pan Li","url":"https://sites.google.com/view/panli-purdue"},{"name":"Dr. Victor Fung","url":"https://cse.gatech.edu/people/victor-fung"}],"logo":"/images/organizations/gt.png"},"prominent":true}],["$","$Lc","Georgia Institute of Technology-1",{"experience":{"title":"M.S. in Computer Science (ML Focus), 4.0 GPA","shortTitle":"M.S. in Computer Science (ML Focus), 4.0 GPA","organization":"Georgia Institute of Technology","organizationUrl":"https://www.gatech.edu/","startDate":"2020","endDate":"2021","highlight":true,"description":["Advisor: Dr. Hyesoon Kim","\"Thank a Teacher\" Award, Georgia Tech Center for Teaching and Learning (2020, 2021)"],"highlightDescription":[],"advisorLinks":[{"name":"Dr. Hyesoon Kim","url":"https://faculty.cc.gatech.edu/~hyesoon/"}],"logo":"/images/organizations/gt.png"},"prominent":true}],["$","$Lc","Georgia Institute of Technology-2",{"experience":{"title":"B.S. in Computer Science (ML Focus), Magna Cum Laude","shortTitle":"B.S. in Computer Science (ML Focus), Magna cum laude","organization":"Georgia Institute of Technology","organizationUrl":"https://www.gatech.edu/","startDate":"2015","endDate":"2019","highlight":true,"description":["ACM SIGBED Student Research Competition Bronze Medal (2019)","Zell Miller Scholarship Recipient (2015 - 2019)"],"highlightDescription":[],"logo":"/images/organizations/gt.png"},"prominent":true}],["$","$Lc","Druid Hills High School-3",{"experience":{"title":"International Baccalaureate Diploma, 4.0 GPA","shortTitle":"International Baccalaureate Diploma, 4.0 GPA","organization":"Druid Hills High School","startDate":"2011","endDate":"2015","highlight":false,"description":[],"highlightDescription":[],"logo":"/images/organizations/druidhills.png"},"prominent":true}]]}]]}],["$","div",null,{"className":"my-12","children":["$","$Ld",null,{}]}],["$","section",null,{"id":"work","className":"py-12","children":[["$","div",null,{"className":"mb-8","children":[["$","h2",null,{"className":"font-serif text-3xl font-bold tracking-tight text-foreground sm:text-4xl","children":"Work Experience"}],["$","p",null,{"className":"mt-2 text-lg text-muted-foreground","children":"My professional and research history"}]]}],["$","div",null,{"className":"grid gap-8","children":[["$","$Lc","ByteDance Research (ByteDance Seed)-0",{"experience":{"id":"bytedance-2025","title":"Research Scientist Intern, AI for Science","organization":"ByteDance Research (ByteDance Seed)","organizationUrl":"https://seed.bytedance.com/en/","startDate":"May 2025","endDate":"Present","location":"Remote","highlight":true,"highlightOrder":1,"description":["Developed foundational spatio-temporal models for protein dynamics, producing realistic conformational ensembles and long-horizon trajectories to support drug-discovery use cases (e.g., mechanism insight and pathway exploration).","Adapted video diffusion with history-aware temporal attention and noise-aware training, improving long-horizon stability/robustness; achieved state-of-the-art quality and diversity/coverage on the ATLAS dataset, with ~33% higher coverage/diversity and ~60% higher quality structures vs. the previous SOTA (in submission).","Built an end-to-end pipeline: protein-dynamics generation → physics-based relaxation (simulator) → quality/diversity evaluation; operated at scale with distributed multi-GPU training and backtesting-style analysis."],"highlightDescription":["Developed foundational spatio-temporal models for protein dynamics, producing realistic conformational ensembles and long-horizon trajectories to support drug-discovery use cases (e.g., mechanism insight and pathway exploration).","Adapted video diffusion with history-aware temporal attention and noise-aware training, improving long-horizon stability/robustness; achieved state-of-the-art quality and diversity/coverage on the ATLAS dataset, with ~33% higher coverage/diversity and ~60% higher quality structures vs. the previous SOTA (in submission).","Built an end-to-end pipeline: protein-dynamics generation → physics-based relaxation (simulator) → quality/diversity evaluation; operated at scale with distributed multi-GPU training and backtesting-style analysis."],"web":{"description":["Developed foundational spatio-temporal models for protein dynamics, producing realistic conformational ensembles and long-horizon trajectories to support drug-discovery use cases (e.g., mechanism insight and pathway exploration).","Adapted video diffusion with history-aware temporal attention and noise-aware training, improving long-horizon stability/robustness; achieved state-of-the-art quality and diversity/coverage on key benchmarks.","Built an end-to-end pipeline: protein-dynamics generation → physics-based relaxation (simulator) → quality/diversity evaluation; operated at scale with distributed multi-GPU training and backtesting-style analysis."],"highlightDescription":["Developed foundational spatio-temporal models for protein dynamics, producing realistic conformational ensembles and long-horizon trajectories to support drug-discovery use cases (e.g., mechanism insight and pathway exploration).","Adapted video diffusion with history-aware temporal attention and noise-aware training, improving long-horizon stability/robustness; achieved state-of-the-art quality and diversity/coverage on key benchmarks.","Built an end-to-end pipeline: protein-dynamics generation → physics-based relaxation (simulator) → quality/diversity evaluation; operated at scale with distributed multi-GPU training and backtesting-style analysis."]},"logo":"/images/organizations/bytedance.png"},"prominent":true}],"$Le","$Lf","$L10","$L11","$L12","$L13","$L14","$L15"]}]]}]]}],["$L16","$L17"],"$L18"]}]
a:["$","$1","h",{"children":[null,["$","$L19",null,{"children":"$@1a"}],["$","div",null,{"hidden":true,"children":["$","$L1b",null,{"children":["$","$1c",null,{"name":"Next.Metadata","children":"$@1d"}]}]}],["$","meta",null,{"name":"next-size-adjust","content":""}]]}]
1e:I[60571,["/_next/static/chunks/04ffb94433a93116.js","/_next/static/chunks/f9e056060c220c2e.js"],"OutletBoundary"]
e:["$","$Lc","Graph Computation and Machine Learning Lab @ GT-1",{"experience":{"id":"gt-gra-2024","title":"Graduate Research Assistant","organization":"Graph Computation and Machine Learning Lab @ GT","organizationUrl":"https://sites.google.com/view/panli-purdue/group","startDate":"Aug 2024","endDate":"Present","location":"Atlanta, GA","highlight":false,"description":["Working with Dr. Pan Li and Dr. Victor Fung on robust fine-tuning strategies for large-scale pre-trained GNN models.","Developed parameter-efficient fine-tuning strategies for machine learning interatomic potentials models trained on the Materials Project dataset, achieving near-SOTA performance on the MatBench Discovery benchmark. (Digital Discovery 2025*)"],"logo":"/images/organizations/gt.png"},"prominent":true}]
f:["$","$Lc","ProcessMiner-2",{"experience":{"id":"processminer-2024","title":"Machine Learning Intern","organization":"ProcessMiner","organizationUrl":"https://processminer.com/","startDate":"June 2024","endDate":"Aug 2024","location":"Atlanta, GA","highlight":true,"highlightOrder":3,"description":["Worked with Dr. Kamran Paynabar to develop novel pre-trained transformer models for manufacturing process data.","Developed transformer models pre-trained on approximately 500,000 time-series data points from manufacturing processes to predict process outcomes and detect anomalies.","Fine-tuned models to achieve accuracy improvements (relative to previous production models) on real-world manufacturing datasets."],"highlightDescription":["Developed transformer models pre-trained on approximately 500,000 time-series data points from manufacturing processes to predict process outcomes and detect anomalies, achieving accuracy improvements on real-world manufacturing datasets."],"logo":"/images/organizations/processminer.png"},"prominent":true}]
10:["$","$Lc","High Performance Computer Architecture Lab @ GT-3",{"experience":{"id":"hparch-staff-2023","title":"Temporary Research Staff","organization":"High Performance Computer Architecture Lab @ GT","organizationUrl":"https://sites.gatech.edu/hparch/","startDate":"Dec 2023","endDate":"May 2024","location":"Atlanta, GA","highlight":false,"combineWith":"hparch-gra-2019","description":["Worked with Dr. Hyesoon Kim and Dr. Stefano Petrangeli on efficient inference strategies for pre-trained image diffusion models, with a focus on generating diverse, high-quality images.","Developed an efficient sampling method for Denoising Diffusion Probabilistic Models (DDPMs) which leverages the structure of the latent space to guide sampling, reducing the number of samples needed for high-quality image generation. (Digital Discovery 2025)"],"logo":"/images/organizations/gt.png"},"prominent":true}]
11:["$","$Lc","Meta Fundamental AI Research (FAIR)-4",{"experience":{"id":"meta-fair-2021","title":"AI Resident, FAIR Chemistry Team","organization":"Meta Fundamental AI Research (FAIR)","organizationUrl":"https://ai.meta.com/research/","teamUrl":"https://fair-chem.github.io/","startDate":"Aug 2021","endDate":"Aug 2023","location":"Menlo Park, CA","highlight":true,"highlightOrder":2,"description":["Worked with Dr. Larry Zitnick, Dr. Abhishek Das, and Dr. Brandon Wood on the Open Catalyst Project, focusing on atomic property prediction and catalyst discovery using large-scale pre-trained models.","Developed large foundation models for atomic property prediction, pre-trained on data from diverse chemical domains. Fine-tuned the model to achieve state-of-the-art results across 35 out of 41 downstream tasks. (ICLR 2024*)","Benchmarked state-of-the-art machine learning interatomic potentials models on the Open Catalyst 2022 dataset, one of the largest datasets for automatic catalyst discovery. (ACS Catalysis 2023)","Co-authored a paper discussing the challenges and potential of developing generalizable machine learning models for catalyst discovery, highlighting the importance of large-scale datasets like the Open Catalyst 2020 Data set (OC20). (ACS Catalysis 2022)","Contributed to the development of a transfer learning approach using Graph Neural Networks to generalize models across domains in molecular and catalyst discovery, reducing the need for large, domain-specific datasets. (J Chem Phys 2022)"],"highlightDescription":["Developed large foundation models for atomic property prediction, pre-trained on data from diverse chemical domains. Fine-tuned the model to achieve state-of-the-art results across 35 out of 41 downstream tasks. (ICLR 2024*)","Contributed to the development of a transfer learning approach using Graph Neural Networks to generalize models across domains in molecular and catalyst discovery, reducing the need for large, domain-specific datasets. (J Chem Phys 2022)","Benchmarked state-of-the-art machine learning interatomic potentials models on the Open Catalyst 2022 dataset, one of the largest datasets for automatic catalyst discovery. (ACS Catalysis 2023)"],"logo":"/images/organizations/meta.png"},"prominent":true}]
12:["$","$Lc","High Performance Computer Architecture Lab @ GT-5",{"experience":{"id":"hparch-gra-2019","title":"Graduate Research Assistant","organization":"High Performance Computer Architecture Lab @ GT","organizationUrl":"https://sites.gatech.edu/hparch/","startDate":"May 2019","endDate":"May 2021","location":"Atlanta, GA","highlight":false,"combinedTitle":"Research Assistant & Research Staff","combinedOrganization":"HPArch Lab @ GT","combinedDates":"May 2019 - May 2021 & Dec 2023 - May 2024","description":["Developed software-level and hardware-level techniques for accelerating deep learning training and inference under the guidance of advisors Dr. Hyesoon Kim and Dr. Moinuddin Qureshi.","Introduced SmaQ, a quantization scheme that leverages the normal distribution of neural network data structures to efficiently quantize them, addressing the memory bottleneck in single-machine training of deep networks. (IEEE CAL 2021*)","Developed NNW-BDI, a neural network weight compression scheme that reduces memory usage by up to 85% without sacrificing inference accuracy on an MNIST classification task. (MemSys 2020*)","Demonstrated the feasibility of running ORB-SLAM2 in real-time on the Raspberry Pi 3B+ for embedded robots through optimizations that achieved a 5x speedup with minor impact on accuracy. (SRC ESWEEK 2019, 3rd Place*)","Co-authored a paper on a context-aware task handling technique for resource-constrained mobile robots, enabling concurrent execution of critical tasks with improved real-time performance. (IEEE Edge 2023)","Contributed to a study that formalized the subsystems of autonomous drones and quantified the complex tradeoffs in their design space to enable optimized solutions for diverse applications. (ASPLOS 2021)","Collaborated on the development of Pisces, a power-aware SLAM implementation that consumes 2.5x less power and executes 7.4x faster than the state of the art by customizing efficient sparse algebra on FPGAs. (DAC 2020)","Participated in an in-depth analysis of the hardware and software components of autonomous drones, characterizing the performance of the ArduCopter flight stack and providing insights to optimize flight controllers and increase drone range. (ISPASS 2020)"],"highlightDescription":["Developed an efficient sampling method for Denoising Diffusion Probabilistic Models (DDPMs) which leverages the structure of the latent space to guide sampling, reducing the number of samples needed for high-quality image generation.","Developed novel quantization techniques for deep learning models, achieving >6x memory savings in training and inference. (MemSys 2020*, IEEE CAL 2021*)"],"logo":"/images/organizations/gt.png"},"prominent":true}]
13:["$","$Lc","Georgia Institute of Technology-6",{"experience":{"id":"gt-ta-2020","title":"Graduate Teaching Assistant","organization":"Georgia Institute of Technology","organizationUrl":"https://www.gatech.edu/","startDate":"Aug 2020","endDate":"May 2021","location":"Atlanta, GA","highlight":false,"description":["Led weekly recitations, graded assignments, and held office hours to help students understand course material for CS 4510: Automata and Complexity, a senior-level undergraduate course on the theory of computation. Taught the course in Fall 2020 with Dr. Merrick Furst and in Spring 2021 with Dr. Zvi Galil.","Received two \"Thank a Teacher\" awards from the Georgia Tech Center for Teaching and Learning in recognition of outstanding contributions and positive impact as a teaching assistant. (2020, 2021)"],"logo":"/images/organizations/gt.png"},"prominent":true}]
14:["$","$Lc","Cyber Forensics Innovation Lab at Georgia Tech-7",{"experience":{"id":"cyfi-2020","title":"Research Assistant","organization":"Cyber Forensics Innovation Lab at Georgia Tech","organizationUrl":"https://cyfi.ece.gatech.edu/","startDate":"Jan 2020","endDate":"Aug 2020","location":"Atlanta, GA","highlight":false,"description":["Developed Graph Neural Network (GNN) based machine learning models to analyze social media data for detecting incoming cyber attacks, under the guidance of advisor Dr. Maria Konte.","Utilized GNNs to effectively capture the complex relationships and patterns within social media networks, enabling early detection and prevention of potential cyber threats."],"logo":"/images/organizations/gt.png"},"prominent":true}]
15:["$","$Lc","Ciena Corporation-8",{"experience":{"id":"ciena-2017","title":"Software Engineering Intern","organization":"Ciena Corporation","organizationUrl":"https://www.ciena.com/","startDate":"May 2017","endDate":"Aug 2018","location":"Atlanta, GA","highlight":false,"description":["Developed software to interface with network devices and maintained CI/CD pipelines for build processes.","Collaborated with cross-functional teams to ensure smooth integration of software components and timely delivery of projects.","Gained valuable experience in software development best practices, version control, and agile methodologies."],"logo":"/images/organizations/ciena.png"},"prominent":true}]
16:["$","script","script-0",{"src":"/_next/static/chunks/602835b498330a9d.js","async":true,"nonce":"$undefined"}]
17:["$","script","script-1",{"src":"/_next/static/chunks/99bc80f84e40b175.js","async":true,"nonce":"$undefined"}]
18:["$","$L1e",null,{"children":["$","$1c",null,{"name":"Next.MetadataOutlet","children":"$@1f"}]}]
1a:[["$","meta","0",{"charSet":"utf-8"}],["$","meta","1",{"name":"viewport","content":"width=device-width, initial-scale=1"}]]
20:I[75022,["/_next/static/chunks/04ffb94433a93116.js","/_next/static/chunks/f9e056060c220c2e.js"],"IconMark"]
1d:[["$","title","0",{"children":"Experience | Nima Shoghi | Nima Shoghi"}],["$","meta","1",{"name":"description","content":"Professional and research experience history."}],["$","meta","2",{"name":"author","content":"Nima Shoghi"}],["$","link","3",{"rel":"manifest","href":"/manifest.json","crossOrigin":"$undefined"}],["$","meta","4",{"name":"keywords","content":"Machine Learning,PhD,Georgia Tech,Deep Learning,AI for Science,Chemistry,Materials Science"}],["$","meta","5",{"name":"creator","content":"Nima Shoghi"}],["$","meta","6",{"name":"robots","content":"index, follow"}],["$","meta","7",{"property":"og:title","content":"Nima Shoghi | ML PhD Student"}],["$","meta","8",{"property":"og:description","content":"PhD student in Machine Learning at Georgia Tech, focusing on Deep Learning for Scientific Applications."}],["$","meta","9",{"property":"og:url","content":"https://nima.sh"}],["$","meta","10",{"property":"og:site_name","content":"Nima Shoghi"}],["$","meta","11",{"property":"og:locale","content":"en_US"}],["$","meta","12",{"property":"og:type","content":"website"}],["$","meta","13",{"name":"twitter:card","content":"summary_large_image"}],["$","meta","14",{"name":"twitter:creator","content":"@nimawrites"}],["$","meta","15",{"name":"twitter:title","content":"Nima Shoghi | ML PhD Student"}],["$","meta","16",{"name":"twitter:description","content":"PhD student in Machine Learning at Georgia Tech, focusing on Deep Learning for Scientific Applications."}],["$","link","17",{"rel":"icon","href":"/favicon.ico","sizes":"any"}],["$","link","18",{"rel":"icon","href":"/favicon.svg","type":"image/svg+xml","media":"(prefers-color-scheme: light)"}],["$","link","19",{"rel":"icon","href":"/favicon-dark.svg","type":"image/svg+xml","media":"(prefers-color-scheme: dark)"}],["$","link","20",{"rel":"icon","href":"/favicon-32.png","type":"image/png","sizes":"32x32"}],["$","link","21",{"rel":"icon","href":"/favicon-16.png","type":"image/png","sizes":"16x16"}],["$","link","22",{"rel":"icon","href":"/favicon-512.png","type":"image/png","sizes":"512x512","media":"(prefers-color-scheme: light)"}],["$","link","23",{"rel":"icon","href":"/favicon-dark-512.png","type":"image/png","sizes":"512x512","media":"(prefers-color-scheme: dark)"}],["$","link","24",{"rel":"apple-touch-icon","href":"/favicon-192.png","sizes":"180x180","type":"image/png"}],["$","$L20","25",{}]]
1f:null
